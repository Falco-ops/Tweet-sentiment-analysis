{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c2379d2",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Connection-to-Azure-ws\" data-toc-modified-id=\"Connection-to-Azure-ws-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Connection to Azure ws</a></span></li><li><span><a href=\"#Datastore\" data-toc-modified-id=\"Datastore-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Datastore</a></span></li><li><span><a href=\"#Define-environment\" data-toc-modified-id=\"Define-environment-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Define environment</a></span></li><li><span><a href=\"#Compute-cluster\" data-toc-modified-id=\"Compute-cluster-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Compute cluster</a></span></li><li><span><a href=\"#Script-preprocessing\" data-toc-modified-id=\"Script-preprocessing-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Script preprocessing</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-ticket",
   "metadata": {},
   "source": [
    "## Connection to Azure ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "instant-polls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.26.0 to work with projet_7\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-maine",
   "metadata": {},
   "source": [
    "## Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "greek-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dirty-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-bankruptcy",
   "metadata": {},
   "source": [
    "## Define environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "straight-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pursuant-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = Environment.from_conda_specification('proj7-h', 'env.yml')\n",
    "#env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-politics",
   "metadata": {},
   "source": [
    "## Compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "auburn-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "standard-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "cluster_name = 'cluster-projet7'\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-distributor",
   "metadata": {},
   "source": [
    "## Script preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "precise-packing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lstm/glove.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lstm/glove.py\n",
    "print('print importing lib...')\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "from azureml.core import Dataset\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import pathlib\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, SimpleRNN, GRU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "import contractions\n",
    "\n",
    "print('lib imported...')\n",
    "# Get script arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n",
    "parser.add_argument(\"--glove-weight\", type=str, dest='glove_dataset_id', help='glove weight')\n",
    "parser.add_argument(\"--batch-size\", type=int, dest='batch_size')\n",
    "parser.add_argument(\"--epoch\", type=int, dest='epoch')\n",
    "parser.add_argument(\"--glove-dim\", type=int, dest='glove_dim')\n",
    "args = parser.parse_args()\n",
    "\n",
    "#set parameters\n",
    "dataset_name = args.training_dataset_id\n",
    "glove_name = args.glove_dataset_id\n",
    "batch_size = args.batch_size\n",
    "epoch = args.epoch\n",
    "glove_dim = args.glove_dim\n",
    "\n",
    "#get the experiment run context and workspace\n",
    "run = Run.get_context()\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "#loading data\n",
    "print(\"loading data...\")\n",
    "data = Dataset.get_by_name(ws, dataset_name).to_pandas_dataframe()\n",
    "glove = Dataset.get_by_name(ws, glove_name).to_pandas_dataframe()\n",
    "\n",
    "################################################################################################################################\n",
    "#                FUNCTION DEFINITION\n",
    "################################################################################################################################\n",
    "\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "\n",
    "#group = regex Return the string matched by the RE.SUB (several match by tweet)\n",
    "\n",
    "def hashtag(text):\n",
    "    text = text.group()\n",
    "    hashtag_body = text[1:]\n",
    "    if hashtag_body.isupper():\n",
    "        result = \"<hashtag> {} <allcaps>\".format(hashtag_body.lower())\n",
    "    else:\n",
    "        result = \" \".join([\"<hashtag>\"] + re.split(r\"(?=[A-Z])\", hashtag_body, flags=FLAGS))\n",
    "    return result\n",
    "\n",
    "def allcaps(text):\n",
    "    text = text.group()\n",
    "    return text.lower()+\" <allcaps> \"\n",
    "\n",
    "def repeat(text):\n",
    "    text = text.group()\n",
    "    t = re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
    "    if text == t:\n",
    "        return text\n",
    "    else:\n",
    "        return t+' <repeat> '\n",
    "\n",
    "def pps_glove(text):\n",
    "    # Different regex parts to combined for smiley faces  \n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`\\-]?\"\n",
    "\n",
    "    # function so code less repetitive\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    #separator for backslash to identify the two words \n",
    "    text = re_sub(r\"/\",\" / \")\n",
    "    text = re_sub(r\"<3\",\"<heart>\")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "    text = re_sub(r\"#\\w+\", hashtag)  \n",
    "    # tag in the word from the repeating letter until the end yeeees ==> text=eees =transform=> es <repeat>\n",
    "    text = re_sub(r'(.)\\1{2,}\\w+', repeat)\n",
    "    # tag repeating letter with a space just before (for this !!!!!!)\n",
    "    text = re_sub(r' (.)\\1{2,}', repeat)\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "    text = re_sub(r\"([a-zA-Z<>()])([?!.:;,])\", r\"\\1 \\2\")\n",
    "    text = re_sub(r\"\\(([a-zA-Z<>]+)\\)\", r\"( \\1 )\")\n",
    "    #flag allcaps \n",
    "    text = re_sub(r\" ([A-Z]){2,} \", allcaps)\n",
    "\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "def contraction(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def remove_apostrophe(text):\n",
    "    return re.sub(r\"['`´()]\", r\" \", text, flags=FLAGS)\n",
    "\n",
    "def seq_to_text(seq):\n",
    "    txt = ' '.join(seq)\n",
    "    return txt\n",
    "\n",
    "##################################################################################################################################\n",
    "#                                                     PREPROCESSING\n",
    "#################################################################################################################################\n",
    "\n",
    "\n",
    "print('start preprocess...')\n",
    "\n",
    "#main function\n",
    "data['text'] = data['text'].apply(pps_glove)\n",
    "\n",
    "#contraction (after smiley and flag)\n",
    "data['text'] = data['text'].apply(contraction)\n",
    "\n",
    "#apostrophre separation for you're, brother's, i'm etc (after contraction) replace with a space\n",
    "data['text'] = data['text'].apply(remove_apostrophe)\n",
    "\n",
    "#turn into word sequence for counter\n",
    "data['text'] = data['text'].apply(lambda x: x.split())\n",
    "\n",
    "################################################################################################################################\n",
    "#                                                 VOCABULARY and EMBEDDING MATRIX\n",
    "################################################################################################################################\n",
    "\n",
    "# load embedding vector from glove xxx dimension into a dict\n",
    "coefs = []\n",
    "word = []\n",
    "word = [w for w in glove.iloc[:,0].values]\n",
    "coefs = [val for val in glove.iloc[:,1:].values]\n",
    "embeddings_index = dict(zip(word, coefs))\n",
    "\n",
    "#vocabulary\n",
    "vocab = Counter()\n",
    "for x in data['text']:\n",
    "    vocab.update(x)\n",
    "    \n",
    "#exatract words appearing only once or twice in the corpus\n",
    "vocab_low_freq = []\n",
    "vocab_low_freq = [w for w,c in vocab.most_common() if c<3]\n",
    "\n",
    "#filter\n",
    "for w in vocab_low_freq:\n",
    "    del vocab[w]\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "#back to text for tokenizer entry\n",
    "print('applying seq to text...')\n",
    "data['text'] = data['text'].apply(seq_to_text)\n",
    "\n",
    "################################################################################################################################\n",
    "#                                                       TOKENIZER AND SPLIT\n",
    "################################################################################################################################\n",
    "\n",
    "X1 = data.text.astype(str)\n",
    "y1 = data.label\n",
    "\n",
    "#Tokenizer / seq and padding\n",
    "t = Tokenizer(num_words=vocab_size)\n",
    "t.fit_on_texts(X1)\n",
    "seq1 = t.texts_to_sequences(X1)\n",
    "\n",
    "#padding\n",
    "seq_pad1 = sequence.pad_sequences(seq1)\n",
    "\n",
    "#embedding matrix de dimension vocab_size glove_dim match our vocabulary with glove vocab\n",
    "embedding_matrix = np.zeros((len(t.word_index)+1, glove_dim))\n",
    "\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "         # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "#determining max length of review\n",
    "max_l = seq_pad1.shape[1]\n",
    "        \n",
    "#split\n",
    "X_train1, X_val1, Y_train1, Y_val1 = train_test_split(seq_pad1, y1, test_size=0.15, random_state=2)\n",
    "\n",
    "################################################################################################################################\n",
    "#                                                       MODEL\n",
    "################################################################################################################################\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "#Embedding\n",
    "model2.add(Embedding(len(t.word_index)+1,\n",
    "                     output_dim = glove_dim,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length = max_l,\n",
    "                     #training false so that weigth are not updated\n",
    "                    trainable=False))\n",
    "\n",
    "#recurrent layer\n",
    "model2.add(LSTM(128, \n",
    "                #basique activation tanh\n",
    "                activation = 'tanh',\n",
    "                #return seq false unless other LSTM layer\n",
    "                return_sequences=False, \n",
    "                dropout=0.1))\n",
    "\n",
    "#fully connected\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "\n",
    "#drop out for overfitting\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "#output layer with sigmoid pour proba\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#compile\n",
    "history = model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']) #, 'AUC'])\n",
    "\n",
    "#Adding callbacks\n",
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1,patience=3)  \n",
    "mc = ModelCheckpoint('best_model_glove', monitor='accuracy', mode='max', save_best_only=True,verbose=1)  \n",
    "\n",
    "################################################################################################################################\n",
    "#                                                       TRAINING\n",
    "################################################################################################################################\n",
    "\n",
    "model2.fit(X_train1,\n",
    "           Y_train1,\n",
    "           epochs=epoch,\n",
    "           batch_size = batch_size,\n",
    "           validation_data = (X_val1, Y_val1),\n",
    "           callbacks=[es, mc])\n",
    "\n",
    "#Evaluate\n",
    "accuracy = model2.evaluate(X_val1, Y_val1) #, auc\n",
    "\n",
    "#load metrics in run\n",
    "run.log_list('accuracy', accuracy)\n",
    "\n",
    "\n",
    "# Save model\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "#os.makedirs('outputs/model', exist_ok=True)\n",
    "# serialize NN architecture to JSON\n",
    "#model_json = model2.to_json()\n",
    "# save model JSON\n",
    "#with open('./outputs/model/model.json', 'w') as f:\n",
    " #   f.write(model_json)\n",
    "# save model weights\n",
    "model2.save('./outputs/glove')\n",
    "\n",
    "# Save the trained model ave joblib\n",
    "#model_file = 'tweet_model.pkl'\n",
    "#joblib.dump(value=model2, filename=model_file)\n",
    "#run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
    "\n",
    "print(\"model saved in ./outputs/model folder\")\n",
    "\n",
    "#Save tokenizer\n",
    "tok_json = t.to_json()\n",
    "with open('./outputs/tok.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tok_json, ensure_ascii=False))\n",
    "    \n",
    "#save mal l and vocab size\n",
    "run.log('max_l', max_l)\n",
    "run.log('vocab_size', vocab_size)\n",
    "dim_emb = len(t.word_index)+1\n",
    "run.log('embedding_dimension', dim_emb)\n",
    "\n",
    "run.complete()\n",
    "\n",
    "# Register the model\n",
    "#print('Registering model...')\n",
    "#run.register_model(model_path='outputs', model_name='tweet_model')\n",
    "\n",
    "# Get the registered model\n",
    "#model = ws.models['tweet_model']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "veterinary-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "democratic-subscriber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad21f694435948baa2843d10c73e8ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/glove_1622661455_c9226d01?wsid=/subscriptions/b9053cbf-be55-4e83-8c03-d6b0eb90cb5a/resourcegroups/Projet_7/workspaces/projet_7&tid=33e47288-d1e1-43e8-b65b-4ba7bfd37a9f\", \"run_id\": \"glove_1622661455_c9226d01\", \"run_properties\": {\"run_id\": \"glove_1622661455_c9226d01\", \"created_utc\": \"2021-06-02T19:17:37.872752Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"68b0eb25-3562-4224-a567-18f951b003f5\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-06-02T19:25:00.673011Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_0d6bd774279a0fdba3550e2dc030debfd290f78185eeba306c8f2282eda854b9_p.txt\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/azureml-logs/55_azureml-execution-tvmps_0d6bd774279a0fdba3550e2dc030debfd290f78185eeba306c8f2282eda854b9_p.txt?sv=2019-02-02&sr=b&sig=oYs9Ob2wp4Te%2BziKAYLDndgtanVeWmK3ApIX9lAv864%3D&st=2021-06-05T15%3A54%3A24Z&se=2021-06-06T00%3A04%3A24Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_0d6bd774279a0fdba3550e2dc030debfd290f78185eeba306c8f2282eda854b9_p.txt\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/azureml-logs/65_job_prep-tvmps_0d6bd774279a0fdba3550e2dc030debfd290f78185eeba306c8f2282eda854b9_p.txt?sv=2019-02-02&sr=b&sig=3AqTu9mRXH3HP13T5VLQuZfm%2FHIpQPgoRmya5b%2BXNTM%3D&st=2021-06-05T15%3A54%3A24Z&se=2021-06-06T00%3A04%3A24Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=YwtDOCFnog3o1fhJudfvv0DvLqC4NkRzk%2FndbE3LiiQ%3D&st=2021-06-05T15%3A54%3A24Z&se=2021-06-06T00%3A04%3A24Z&sp=r\", \"azureml-logs/75_job_post-tvmps_0d6bd774279a0fdba3550e2dc030debfd290f78185eeba306c8f2282eda854b9_p.txt\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/azureml-logs/75_job_post-tvmps_0d6bd774279a0fdba3550e2dc030debfd290f78185eeba306c8f2282eda854b9_p.txt?sv=2019-02-02&sr=b&sig=%2F0fudYYTcUaSp5GCo35iUir8IVgcVhONKkmUIvqMg4Q%3D&st=2021-06-05T15%3A54%3A24Z&se=2021-06-06T00%3A04%3A24Z&sp=r\", \"azureml-logs/process_info.json\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=ZE%2BI04FFZRxoUBmutC5wznjQa%2F1yPvWqCWY38fODYkE%3D&st=2021-06-05T15%3A54%3A24Z&se=2021-06-06T00%3A04%3A24Z&sp=r\", \"azureml-logs/process_status.json\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=Xr8mRQ9UnpxOkFklk%2Bf1nduqdmMe%2BLT9vtKwfy2KrbY%3D&st=2021-06-05T15%3A54%3A24Z&se=2021-06-06T00%3A04%3A24Z&sp=r\", \"logs/azureml/111_azureml.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/logs/azureml/111_azureml.log?sv=2019-02-02&sr=b&sig=fIv2aUf0f1OvSpkgyz26sHSwZ88Yr4zYzA9SOCVSRvs%3D&st=2021-06-05T15%3A54%3A24Z&se=2021-06-06T00%3A04%3A24Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=f68L48Ljcf50aYwBb10O9147EPU1aDAYUT%2BtXX3Hy1g%3D&st=2021-06-05T15%3A54%3A24Z&se=2021-06-06T00%3A04%3A24Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=8U1IjgpdEHKHyqheLZK%2FMjERU%2FeyfbtCdXiN5jHa0Zw%3D&st=2021-06-05T15%3A54%3A24Z&se=2021-06-06T00%3A04%3A24Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=poWwWn%2Bp0Svh3vFREgCOfwRqpoDZwIJkq4hnnhGGEBw%3D&st=2021-06-05T15%3A54%3A24Z&se=2021-06-06T00%3A04%3A24Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=WG5Y5BCf0%2BZICNRxw0d4NS%2FPLdBSpu2w9lcj2wX8FAI%3D&st=2021-06-05T15%3A54%3A24Z&se=2021-06-06T00%3A04%3A24Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_0d6bd774279a0fdba3550e2dc030debfd290f78185eeba306c8f2282eda854b9_p.txt\"], [\"azureml-logs/65_job_prep-tvmps_0d6bd774279a0fdba3550e2dc030debfd290f78185eeba306c8f2282eda854b9_p.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_0d6bd774279a0fdba3550e2dc030debfd290f78185eeba306c8f2282eda854b9_p.txt\"], [\"logs/azureml/111_azureml.log\"]], \"run_duration\": \"0:07:22\", \"run_number\": \"1622661457\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"accuracy\", \"run_id\": \"glove_1622661455_c9226d01\", \"categories\": [0, 1], \"series\": [{\"data\": [0.5932837128639221, 0.6959999799728394]}]}], \"run_logs\": \"2021-06-02 19:21:44,045|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2021-06-02 19:21:44,046|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2021-06-02 19:21:44,118|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2021-06-02 19:21:44,118|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2021-06-02 19:21:44,520|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f6640c15160> for run source azureml.scriptrun\\n2021-06-02 19:21:44,521|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-06-02 19:21:44,521|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-06-02 19:21:44,523|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-06-02 19:21:44,558|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2021-06-02 19:21:44,558|azureml.core.authentication|DEBUG|Time to expire 1814152.441449 seconds\\n2021-06-02 19:21:44,558|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2021-06-02 19:21:44,559|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2021-06-02 19:21:44,590|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:21:44,590|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:21:44,591|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:21:44,591|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:21:44,591|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:21:44,591|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:21:44,591|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:21:44,633|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-06-02 19:21:44,633|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-06-02 19:21:44,702|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-06-02 19:21:44,703|azureml._SubmittedRun#glove_1622661455_c9226d01|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '68b0eb25-3562-4224-a567-18f951b003f5', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-06-02 19:21:44,703|azureml._SubmittedRun#glove_1622661455_c9226d01.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-06-02 19:21:44,703|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2021-06-02 19:21:44,703|azureml.WorkerPool|DEBUG|[START]\\n2021-06-02 19:21:44,703|azureml.SendRunKillSignal|DEBUG|[START]\\n2021-06-02 19:21:44,703|azureml.RunStatusContext|DEBUG|[START]\\n2021-06-02 19:21:44,704|azureml._SubmittedRun#glove_1622661455_c9226d01.RunContextManager.RunStatusContext|DEBUG|[START]\\n2021-06-02 19:21:44,704|azureml.MetricsClient|DEBUG|[START]\\n2021-06-02 19:21:44,704|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2021-06-02 19:21:44,704|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2021-06-02 19:21:44,704|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2021-06-02 19:21:44,704|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/glove_1622661455_c9226d01/mounts/workspaceblobstore/azureml/glove_1622661455_c9226d01\\n2021-06-02 19:21:44,704|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-06-02 19:21:44,704|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/glove_1622661455_c9226d01/mounts/workspaceblobstore/azureml/glove_1622661455_c9226d01\\n2021-06-02 19:22:14,523|azureml.core.authentication|DEBUG|Time to expire 1814122.476256 seconds\\n2021-06-02 19:22:20,077|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-06-02 19:22:20,077|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-06-02 19:22:20,077|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-06-02 19:22:20,078|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:20,078|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:20,078|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:20,078|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:20,079|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:20,079|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:20,079|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:20,101|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-06-02 19:22:20,101|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-06-02 19:22:20,181|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-06-02 19:22:20,181|azureml._SubmittedRun#glove_1622661455_c9226d01|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '68b0eb25-3562-4224-a567-18f951b003f5', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-06-02 19:22:20,181|azureml._SubmittedRun#glove_1622661455_c9226d01.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-06-02 19:22:20,460|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-06-02 19:22:20,461|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-06-02 19:22:20,461|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-06-02 19:22:20,462|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:20,463|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:20,464|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:20,464|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:20,471|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:20,472|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:20,472|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:32,077|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-06-02 19:22:32,077|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-06-02 19:22:32,078|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-06-02 19:22:32,078|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:32,079|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:32,079|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:32,079|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:32,080|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:32,080|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:32,080|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:32,086|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[START]\\n2021-06-02 19:22:32,086|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling patch_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-06-02 19:22:32,260|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[STOP]\\n2021-06-02 19:22:35,040|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-06-02 19:22:35,040|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-06-02 19:22:35,040|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-06-02 19:22:35,040|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:35,041|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:35,041|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:35,041|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:35,041|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:35,041|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:35,042|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-02 19:22:35,049|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[START]\\n2021-06-02 19:22:35,049|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling patch_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-06-02 19:22:35,160|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[STOP]\\n2021-06-02 19:22:44,531|azureml.core.authentication|DEBUG|Time to expire 1814092.468205 seconds\\n2021-06-02 19:23:14,535|azureml.core.authentication|DEBUG|Time to expire 1814062.464844 seconds\\n2021-06-02 19:23:44,535|azureml.core.authentication|DEBUG|Time to expire 1814032.46437 seconds\\n2021-06-02 19:24:14,538|azureml.core.authentication|DEBUG|Time to expire 1814002.461341 seconds\\n2021-06-02 19:24:26,814|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-06-02 19:24:26,814|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-06-02 19:24:26,818|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-06-02 19:24:27,819|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-06-02 19:24:27,819|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-06-02 19:24:27,819|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 1.\\n2021-06-02 19:24:27,820|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-06-02 19:24:27,820|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-06-02 19:24:27,820|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-06-02 19:24:27,820|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 1 values.\\n2021-06-02 19:24:27,820|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-06-02 19:24:27,820|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-06-02 19:24:27,820|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-06-02 19:24:27,821|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-06-02 19:24:27,821|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2021-06-02 19:24:27,821|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-06-02 19:24:27,821|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-06-02 19:24:27,823|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-06-02 19:24:27,823|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-06-02 19:24:27,825|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-06-02 19:24:27,825|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-06-02 19:24:27,826|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2021-06-02 19:24:27,826|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-06-02 19:24:28,020|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-06-02 19:24:34,014|azureml._SubmittedRun#glove_1622661455_c9226d01|INFO|complete is not setting status for submitted runs.\\n2021-06-02 19:24:34,016|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-06-02 19:24:34,016|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-06-02 19:24:34,016|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-06-02 19:24:34,016|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-06-02 19:24:34,016|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-02 19:24:34,017|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-06-02 19:24:34,017|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-06-02 19:24:34,017|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-06-02 19:24:34,017|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-02 19:24:34,017|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-02 19:24:34,017|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-06-02 19:24:34,017|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2021-06-02 19:24:34,017|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2021-06-02 19:24:34,017|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2021-06-02 19:24:34,017|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2021-06-02 19:24:34,017|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-06-02 19:24:34,017|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-02 19:24:34,018|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-06-02 19:24:34,018|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-06-02 19:24:34,018|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-06-02 19:24:34,111|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-06-02 19:24:34,112|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: [], excluding []\\n2021-06-02 19:24:34,112|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2021-06-02 19:24:34,281|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-06-02 19:24:34,281|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/glove_1622661455_c9226d01/mounts/workspaceblobstore/azureml/glove_1622661455_c9226d01\\n2021-06-02 19:24:34,281|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/glove_1622661455_c9226d01/mounts/workspaceblobstore/azureml/glove_1622661455_c9226d01 to /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/glove_1622661455_c9226d01/mounts/workspaceblobstore/azureml/glove_1622661455_c9226d01\\n2021-06-02 19:24:34,281|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/glove_1622661455_c9226d01/mounts/workspaceblobstore/azureml/glove_1622661455_c9226d01\\n2021-06-02 19:24:34,281|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2021-06-02 19:24:34,281|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2021-06-02 19:24:34,281|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-06-02 19:24:34,282|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-06-02 19:24:34,282|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-06-02 19:24:34,282|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-06-02 19:24:34,282|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-02 19:24:34,282|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-06-02 19:24:34,282|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-06-02 19:24:34,282|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-06-02 19:24:34,282|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-02 19:24:34,282|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-06-02 19:24:34,282|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-06-02 19:24:34,283|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-06-02 19:24:34,283|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-02 19:24:34,283|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-06-02 19:24:34,283|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-06-02 19:24:34,283|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-06-02 19:24:34,283|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-02 19:24:34,283|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-06-02 19:24:34,283|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-06-02 19:24:34,283|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-06-02 19:24:34,369|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-06-02 19:24:34,369|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient|DEBUG|[STOP]\\n2021-06-02 19:24:34,369|azureml.MetricsClient|DEBUG|[STOP]\\n2021-06-02 19:24:34,369|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-06-02 19:24:34,369|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-02 19:24:34,369|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-06-02 19:24:34,369|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-06-02 19:24:34,370|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-06-02 19:24:34,370|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-02 19:24:34,370|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-02 19:24:34,370|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-06-02 19:24:34,370|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-06-02 19:24:34,370|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-06-02 19:24:34,370|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-02 19:24:34,370|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-06-02 19:24:34,370|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-06-02 19:24:34,370|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-06-02 19:24:34,446|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-06-02 19:24:34,446|azureml.RunStatusContext|DEBUG|[STOP]\\n2021-06-02 19:24:34,446|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-06-02 19:24:34,446|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-02 19:24:34,446|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-06-02 19:24:34,446|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-06-02 19:24:34,446|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-06-02 19:24:34,447|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-02 19:24:34,447|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-02 19:24:34,447|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-06-02 19:24:34,447|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-06-02 19:24:34,447|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-06-02 19:24:34,447|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-02 19:24:34,447|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-06-02 19:24:34,447|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-06-02 19:24:34,447|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-06-02 19:24:34,528|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-06-02 19:24:34,529|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-06-02 19:24:34,529|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-02 19:24:34,529|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-06-02 19:24:34,529|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-06-02 19:24:34,529|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-06-02 19:24:34,529|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-02 19:24:34,529|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-02 19:24:34,529|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-06-02 19:24:34,530|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-06-02 19:24:34,530|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-06-02 19:24:34,530|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-02 19:24:34,530|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-06-02 19:24:34,530|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-06-02 19:24:34,530|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-06-02 19:24:34,621|azureml._SubmittedRun#glove_1622661455_c9226d01.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-06-02 19:24:34,621|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2021-06-02 19:24:34,621|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2021-06-02 19:24:34,621|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2021-06-02 19:24:34,622|azureml.WorkerPool|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.26.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'glove_1622661455_c9226d01',\n",
       " 'target': 'cluster-projet7',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2021-06-02T19:20:51.036267Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': '68b0eb25-3562-4224-a567-18f951b003f5',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '8d7b3d11-ae66-4cc3-a146-8fdcb3836526'}, 'consumptionDetails': {'type': 'Reference'}}, {'dataset': {'id': '23e04031-94f7-4c03-b693-23cb0236fa9e'}, 'consumptionDetails': {'type': 'Reference'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'glove.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--input-data',\n",
       "   'sample',\n",
       "   '--glove-dim',\n",
       "   '25',\n",
       "   '--glove-weight',\n",
       "   'glove-25d',\n",
       "   '--batch-size',\n",
       "   '32',\n",
       "   '--epoch',\n",
       "   '5'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'cluster-projet7',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'proj7-h',\n",
       "   'version': '7',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge', 'defaults'],\n",
       "     'dependencies': ['pip',\n",
       "      'pandas',\n",
       "      'scikit-learn',\n",
       "      'nltk',\n",
       "      'python=3.8',\n",
       "      'tensorflow',\n",
       "      'numpy=1.18.5',\n",
       "      'ipykernel',\n",
       "      'notebook',\n",
       "      'pyahocorasick',\n",
       "      'keras',\n",
       "      {'pip': ['azureml-core', 'azureml-dataset-runtime', 'contractions']}],\n",
       "     'name': 'azureml_ca6b2b150ca6091db30bfc50f017762f'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_0d6bd774279a0fdba3550e2dc030debfd290f78185eeba306c8f2282eda854b9_p.txt': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/azureml-logs/55_azureml-execution-tvmps_0d6bd774279a0fdba3550e2dc030debfd290f78185eeba306c8f2282eda854b9_p.txt?sv=2019-02-02&sr=b&sig=2YuRJCV0NdB0oIxJBWMFthwtP6SPsMzwpE8BfRlHfno%3D&st=2021-06-02T19%3A14%3A55Z&se=2021-06-03T03%3A24%3A55Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_0d6bd774279a0fdba3550e2dc030debfd290f78185eeba306c8f2282eda854b9_p.txt': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/azureml-logs/65_job_prep-tvmps_0d6bd774279a0fdba3550e2dc030debfd290f78185eeba306c8f2282eda854b9_p.txt?sv=2019-02-02&sr=b&sig=FV6s39L%2FAinF9W%2BCU72bUx%2BMB3A8CXNeHWfUVli%2FUa8%3D&st=2021-06-02T19%3A14%3A55Z&se=2021-06-03T03%3A24%3A55Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=jhUO5OIuGcD%2BqBhz8hUyEKrovQEIanqZdJDLHgXIHpg%3D&st=2021-06-02T19%3A14%3A55Z&se=2021-06-03T03%3A24%3A55Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_0d6bd774279a0fdba3550e2dc030debfd290f78185eeba306c8f2282eda854b9_p.txt': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/azureml-logs/75_job_post-tvmps_0d6bd774279a0fdba3550e2dc030debfd290f78185eeba306c8f2282eda854b9_p.txt?sv=2019-02-02&sr=b&sig=gnZpAG7RtzbUzFAXSbVYP1Jxk0QUrRbXbsn1GVREC2I%3D&st=2021-06-02T19%3A14%3A55Z&se=2021-06-03T03%3A24%3A55Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=TJKXk31LYIGoxXeqD4nplfpKt5rvT33drqqEDVfh9ig%3D&st=2021-06-02T19%3A14%3A55Z&se=2021-06-03T03%3A24%3A55Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=rYvEwlXf%2B%2BPsHP5hnAx2Fld4%2FnKlDNMxi9dFS6jECu4%3D&st=2021-06-02T19%3A14%3A55Z&se=2021-06-03T03%3A24%3A55Z&sp=r',\n",
       "  'logs/azureml/111_azureml.log': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/logs/azureml/111_azureml.log?sv=2019-02-02&sr=b&sig=FIKE16lwq2loIBqQ%2FRN27sP052Q6zAhZojhTNT4hpZ8%3D&st=2021-06-02T19%3A14%3A55Z&se=2021-06-03T03%3A24%3A55Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=dYDTS4riLzqf7S%2FMx92V7yBfUj3UqVE30frPu9RhraE%3D&st=2021-06-02T19%3A14%3A55Z&se=2021-06-03T03%3A24%3A55Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=7dRZ5ducbfucaWlJTlq0z4gELTvD6rBNyGfK%2BjaTW1k%3D&st=2021-06-02T19%3A14%3A55Z&se=2021-06-03T03%3A24%3A55Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=9HNxDCUudYF%2Bfa6f7wGOezSZd01MoMsqeYOG%2BGVb6LI%3D&st=2021-06-02T19%3A14%3A55Z&se=2021-06-03T03%3A24%3A55Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1622661455_c9226d01/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=yg4%2BMIuF8bAX9NZXMwxa7YRUKtNpp2FWCMTQe2dzCCs%3D&st=2021-06-02T19%3A14%3A55Z&se=2021-06-03T03%3A24%3A55Z&sp=r'},\n",
       " 'submittedBy': 'Axel Favreul'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the registered environment\n",
    "registered_env = Environment.get(ws, 'proj7-h')\n",
    "\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory='lstm',\n",
    "                                script='glove.py',\n",
    "                                arguments = ['--input-data', 'sample',\n",
    "                                            '--glove-dim', 25,\n",
    "                                            '--glove-weight', 'glove-25d',\n",
    "                                            '--batch-size', 32,\n",
    "                                            '--epoch', 5],\n",
    "                                environment=registered_env,\n",
    "                                compute_target=cluster_name) \n",
    "\n",
    "# submit the experiment\n",
    "experiment_name = 'glove'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a37fe85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size 6963\n"
     ]
    }
   ],
   "source": [
    "metrics = run.get_metrics()\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3c9807a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml-logs/55_azureml-execution-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt\n",
      "azureml-logs/65_job_prep-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt\n",
      "azureml-logs/70_driver_log.txt\n",
      "azureml-logs/75_job_post-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt\n",
      "azureml-logs/process_info.json\n",
      "azureml-logs/process_status.json\n",
      "logs/azureml/111_azureml.log\n",
      "logs/azureml/dataprep/backgroundProcess.log\n",
      "logs/azureml/dataprep/backgroundProcess_Telemetry.log\n",
      "logs/azureml/job_prep_azureml.log\n",
      "logs/azureml/job_release_azureml.log\n",
      "outputs/sample-pre.csv\n"
     ]
    }
   ],
   "source": [
    "for file in run.get_file_names():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0d4fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj7",
   "language": "python",
   "name": "proj7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
