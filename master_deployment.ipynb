{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "910b7913",
   "metadata": {},
   "source": [
    "## Library for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a22dcfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import pathlib\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing.text import text_to_word_sequence, tokenizer_from_json\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372e6d0f",
   "metadata": {},
   "source": [
    "## Connect to workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca40fa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.26.0 to work with projet_7\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3693dee1",
   "metadata": {},
   "source": [
    "## Get data from experiment run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63625a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 'glove_1622827159_36953bd1'\n",
    "run1 = ws.get_run(run_id)\n",
    "v = run1.get_metrics()\n",
    "max_l = v['max_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "989b62af",
   "metadata": {},
   "outputs": [],
   "source": [
    "run1.download_file('outputs/tok.json', output_file_path='tok1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "065146f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tok1.json') as f:\n",
    "    data = json.load(f)\n",
    "    t = tokenizer_from_json(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77616521",
   "metadata": {},
   "source": [
    "## Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a5e759ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97371fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_sample\tglove_sample:4\t4\n"
     ]
    }
   ],
   "source": [
    "model2 = run1.register_model(model_name='glove_sample',\n",
    "                           tags={'max_l': '45'},\n",
    "                           model_path='outputs/glove')\n",
    "print(model2.name, model2.id, model2.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c40664",
   "metadata": {},
   "source": [
    "## Load environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37944dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "210545e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment.from_conda_specification('proj7-h', 'env.yml')\n",
    "#registered_env = Environment.get(ws, 'proj7-h')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f74835e",
   "metadata": {},
   "source": [
    "## Add azureml default to environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f6b5dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda_dep = CondaDependencies()\n",
    "#conda_dep.add_pip_package(\"azureml-defaults\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7267605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#registered_env.python.conda_dependencies=conda_dep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a9951",
   "metadata": {},
   "source": [
    "## Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0a15dc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting source_dir/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile source_dir/score.py\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import pathlib\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing.text import text_to_word_sequence, tokenizer_from_json\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "import contractions\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "\n",
    "\n",
    "def init():\n",
    "    \n",
    "    global model\n",
    "    model_root = Model.get_model_path('glove_sample')\n",
    "    #model_root_dl = os.path.join(model_root, 'glove')\n",
    "    model = load_model(model_root, compile=True)\n",
    "    print('this is init')\n",
    "\n",
    "\n",
    "def run(data):\n",
    "    data = json.loads(data)\n",
    "    \n",
    "    #load data into list\n",
    "    L = []\n",
    "    for key in data:\n",
    "        L.append(data[key])\n",
    "    \n",
    "    #load data into dataframe \n",
    "    df = pd.DataFrame(L, columns={'text'})\n",
    "    \n",
    "    #preprocess text\n",
    "    X = pre_pro(df, 45)\n",
    "    \n",
    "    #make prediction\n",
    "    prediction = model.predict(X)\n",
    "    \n",
    "    #load result into nested json\n",
    "    outputs = {}\n",
    "\n",
    "    for key in data:\n",
    "    #for i in range(0,len(prediction)):\n",
    "        text = {}\n",
    "        i = int(key)\n",
    "        text['text'] = data[key]\n",
    "        text['score'] = float(prediction[i])\n",
    "        if prediction[i]>0.5:\n",
    "            text['sentiment'] = 'positive'\n",
    "        else:\n",
    "            text['sentiment'] = 'negative'\n",
    "\n",
    "        outputs[i]=text    \n",
    "    \n",
    "    return outputs\n",
    "    #return f\"test is {prediction}\"\n",
    "\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "\n",
    "#group = regex Return the string matched by the RE.SUB (several match by tweet)\n",
    "\n",
    "def hashtag(text):\n",
    "    text = text.group()\n",
    "    hashtag_body = text[1:]\n",
    "    if hashtag_body.isupper():\n",
    "        result = \"<hashtag> {} <allcaps>\".format(hashtag_body.lower())\n",
    "    else:\n",
    "        result = \" \".join([\"<hashtag>\"] + re.split(r\"(?=[A-Z])\", hashtag_body, flags=FLAGS))\n",
    "    return result\n",
    "\n",
    "def allcaps(text):\n",
    "    text = text.group()\n",
    "    return text.lower()+\" <allcaps> \"\n",
    "\n",
    "def repeat(text):\n",
    "    text = text.group()\n",
    "    t = re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
    "    if text == t:\n",
    "        return text\n",
    "    else:\n",
    "        return t+' <repeat> '\n",
    "\n",
    "def pps_glove(text):\n",
    "    # Different regex parts to combined for smiley faces  \n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`\\-]?\"\n",
    "\n",
    "    # function so code less repetitive\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    #separator for backslash to identify the two words \n",
    "    text = re_sub(r\"/\",\" / \")\n",
    "    text = re_sub(r\"<3\",\"<heart>\")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "    text = re_sub(r\"#\\w+\", hashtag)  \n",
    "    # tag in the word from the repeating letter until the end yeeees ==> text=eees =transform=> es <repeat>\n",
    "    text = re_sub(r'(.)\\1{2,}\\w+', repeat)\n",
    "    # tag repeating letter with a space just before (for this !!!!!!)\n",
    "    text = re_sub(r' (.)\\1{2,}', repeat)\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "    text = re_sub(r\"([a-zA-Z<>()])([?!.:;,])\", r\"\\1 \\2\")\n",
    "    text = re_sub(r\"\\(([a-zA-Z<>]+)\\)\", r\"( \\1 )\")\n",
    "    #flag allcaps \n",
    "    text = re_sub(r\" ([A-Z]){2,} \", allcaps)\n",
    "\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "def contraction(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def remove_apostrophe(text):\n",
    "    return re.sub(r\"['`Â´()]\", r\" \", text, flags=FLAGS)\n",
    "\n",
    "def pre_pro(data, dim):\n",
    "    #main function\n",
    "    data['text'] = data['text'].apply(pps_glove)\n",
    "\n",
    "    #contraction (after smiley and flag)\n",
    "    data['text'] = data['text'].apply(contraction)\n",
    "\n",
    "    #apostrophre separation for you're, brother's, i'm etc (after contraction) replace with a space\n",
    "    data['text'] = data['text'].apply(remove_apostrophe)\n",
    "    \n",
    "    X = data.text.astype(str)\n",
    "    \n",
    "    with open('./source_dir/tok1.json') as f:\n",
    "        data = json.load(f)\n",
    "        t = tokenizer_from_json(data)\n",
    "    \n",
    "    seq = t.texts_to_sequences(X)\n",
    "    \n",
    "    seq_pad = sequence.pad_sequences(seq, maxlen=dim)\n",
    "   \n",
    "    return seq_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7514b3",
   "metadata": {},
   "source": [
    "## Inference Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c8b6e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "6ac2f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(\n",
    "    environment=env,\n",
    "    source_directory=\"./source_dir\",\n",
    "    entry_script=\"./score.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb3e804",
   "metadata": {},
   "source": [
    "## Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "22221765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d782e11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model glove_sample:4 to C:\\Users\\favre\\AppData\\Local\\Temp\\azureml_t6uhea82\\glove_sample\\4\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry 38d02f2005824c85859d3a5c11c9a143.azurecr.io\n",
      "Logging into Docker registry 38d02f2005824c85859d3a5c11c9a143.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM 38d02f2005824c85859d3a5c11c9a143.azurecr.io/azureml/azureml_e445f60a37dcdf195e0bfe84260151b7\n",
      " ---> 48b62ad833b7\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 5faf7a18ee9d\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6ImI5MDUzY2JmLWJlNTUtNGU4My04YzAzLWQ2YjBlYjkwY2I1YSIsInJlc291cmNlR3JvdXBOYW1lIjoicHJvamV0XzciLCJhY2NvdW50TmFtZSI6InByb2pldF83Iiwid29ya3NwYWNlSWQiOiIzOGQwMmYyMC0wNTgyLTRjODUtODU5ZC0zYTVjMTFjOWExNDMifSwibW9kZWxzIjp7fSwibW9kZWxzSW5mbyI6e319 | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in c01313c76e65\n",
      " ---> 0a97054cd30a\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpvmjw2vto.py' /var/azureml-app/main.py\n",
      " ---> Running in 487e55534b01\n",
      " ---> b96c0152ee27\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 7212da82c568\n",
      " ---> e487c556b505\n",
      "Successfully built e487c556b505\n",
      "Successfully tagged myservice:latest\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:761f212388e627b686ba4a7f4a9dd403e9a934a92c470ab94aa15ceb283791c8 successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:6789\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(\n",
    "    ws,\n",
    "    \"myservice\",\n",
    "    [model2],\n",
    "    inference_config,\n",
    "    deployment_config,\n",
    "    overwrite=True,\n",
    ")\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ea5498",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "75496c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'text': '@dider the movie was really baaaaad, catastrophic acting :-(',\n",
       "  'score': 0.3742055892944336,\n",
       "  'sentiment': 'negative'},\n",
       " '1': {'text': 'OMG what an awesome concert !!!!!!! so good :-)',\n",
       "  'score': 0.893543541431427,\n",
       "  'sentiment': 'positive'},\n",
       " '2': {'text': '@dider the movie was really baaaaad, catastrophic acting',\n",
       "  'score': 0.4965532422065735,\n",
       "  'sentiment': 'negative'}}"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "uri = service.scoring_uri\n",
    "requests.get(\"http://localhost:6789\")\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "data = {\n",
    "    0: \"@dider the movie was really baaaaad, catastrophic acting :-(\",\n",
    "    1: \"OMG what an awesome concert !!!!!!! so good :-)\",\n",
    "    2: \"@dider the movie was really baaaaad, catastrophic acting\"\n",
    "}\n",
    "data = json.dumps(data)\n",
    "response = requests.post(uri, data=data, headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268c28f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj7",
   "language": "python",
   "name": "proj7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
