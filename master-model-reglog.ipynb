{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e820b4",
   "metadata": {},
   "source": [
    "## Worspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67530a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.26.0 to work with projet_7\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d49cd3",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "970b673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bae04641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "cluster_name = 'cluster-projet7'\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af326cfe",
   "metadata": {},
   "source": [
    "## Script model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936c6e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lstm/model-logreg.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lstm/model-logreg.py\n",
    "print('print importing lib...')\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "from azureml.core import Dataset\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "print('lib imported...')\n",
    "\n",
    "# Get script arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--run-id', type=str, dest='run_id', help='run id to get preprocessed data')\n",
    "parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n",
    "args = parser.parse_args()\n",
    "\n",
    "#set parameters\n",
    "run_id = args.run_id\n",
    "dataset_name = args.training_dataset_id\n",
    "\n",
    "#workspace and run\n",
    "run = Run.get_context()\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "print('get vocab size...')\n",
    "#get vocab_size from preprocessing run\n",
    "run1 = ws.get_run(run_id)\n",
    "v = run1.get_metrics()\n",
    "vocab_size = v['vocab_size']\n",
    "print('vocab size loaded...')\n",
    "\n",
    "#get dataset\n",
    "print(\"loading data...\")\n",
    "data = Dataset.get_by_name(ws, dataset_name).to_pandas_dataframe()\n",
    "print(\"data loaded...\")\n",
    "\n",
    "#change text type from object to string\n",
    "data['text'] = data['text'].astype(str)\n",
    "\n",
    "#text to vect. Mindf=2 to get rid of term appearing only in 2 tweets\n",
    "cv = CountVectorizer(min_df=2)\n",
    "cv.fit(data['text'])\n",
    "\n",
    "#split\n",
    "X = cv.transform(data['text'])\n",
    "y = data['label']\n",
    "\n",
    "\n",
    "#splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "# Scaler\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "# Scaling\n",
    "scaler.fit(X_train)\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "#run test for different value of c\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c, solver='saga', max_iter=200)\n",
    "    lr.fit(X_train_scale, y_train)\n",
    "    print('Accuracy for C=%s: %s'\n",
    "         % (c, accuracy_score(y_test, lr.predict(X_test_scale))))\n",
    "\n",
    "\n",
    "run.complete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48891619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc4664",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9490153",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_env = Environment.get(ws, 'proj7-h')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a215f5",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ebb8be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2adb63f5c2c49b29e82a6f10e153514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/model-logreg_1621169534_9756326b?wsid=/subscriptions/b9053cbf-be55-4e83-8c03-d6b0eb90cb5a/resourcegroups/Projet_7/workspaces/projet_7&tid=33e47288-d1e1-43e8-b65b-4ba7bfd37a9f\", \"run_id\": \"model-logreg_1621169534_9756326b\", \"run_properties\": {\"run_id\": \"model-logreg_1621169534_9756326b\", \"created_utc\": \"2021-05-16T12:52:15.947562Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"a5ca8c3a-a582-4bb4-837b-e75594558db8\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-05-16T13:02:29.757027Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_e5653443bc62c73b3418f0c71f7af29a68c0ea74ad941cc3f81d61c8c4a1656b_p.txt\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/azureml-logs/55_azureml-execution-tvmps_e5653443bc62c73b3418f0c71f7af29a68c0ea74ad941cc3f81d61c8c4a1656b_p.txt?sv=2019-02-02&sr=b&sig=K34VdtdGhljgdcV9viXOf5Zou2iktCZFWeXv35ACKmg%3D&st=2021-05-19T19%3A12%3A38Z&se=2021-05-20T03%3A22%3A38Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_e5653443bc62c73b3418f0c71f7af29a68c0ea74ad941cc3f81d61c8c4a1656b_p.txt\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/azureml-logs/65_job_prep-tvmps_e5653443bc62c73b3418f0c71f7af29a68c0ea74ad941cc3f81d61c8c4a1656b_p.txt?sv=2019-02-02&sr=b&sig=Wc9fVc6S%2F1rfzwLOnJVOUSZ641PeGCx1cGoaclM7Dlk%3D&st=2021-05-19T19%3A12%3A38Z&se=2021-05-20T03%3A22%3A38Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=hxHWGNEkfIxfshvgiMGYpdvC5rkY%2F8%2B4Dspb%2FmvNvrg%3D&st=2021-05-19T19%3A12%3A38Z&se=2021-05-20T03%3A22%3A38Z&sp=r\", \"azureml-logs/75_job_post-tvmps_e5653443bc62c73b3418f0c71f7af29a68c0ea74ad941cc3f81d61c8c4a1656b_p.txt\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/azureml-logs/75_job_post-tvmps_e5653443bc62c73b3418f0c71f7af29a68c0ea74ad941cc3f81d61c8c4a1656b_p.txt?sv=2019-02-02&sr=b&sig=0wWuEcavSasENggKjfxA9jC3ZmyxdGwmGwODaEUrVtM%3D&st=2021-05-19T19%3A12%3A38Z&se=2021-05-20T03%3A22%3A38Z&sp=r\", \"azureml-logs/process_info.json\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=P1sAOTbpjMWR4YXjQJ4G35T8nZek1%2BU7l0pO6lsnJMY%3D&st=2021-05-19T19%3A12%3A38Z&se=2021-05-20T03%3A22%3A38Z&sp=r\", \"azureml-logs/process_status.json\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=83%2Bwqo7SQS7CEE2TX1O3Oy3Eo9d%2F5E2G1%2B2D5zflLak%3D&st=2021-05-19T19%3A12%3A38Z&se=2021-05-20T03%3A22%3A38Z&sp=r\", \"logs/azureml/111_azureml.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/logs/azureml/111_azureml.log?sv=2019-02-02&sr=b&sig=gO5dxcrRDbK%2FSUQvkuWPHz8pPU5lIp2vEdWIa%2BCvUWM%3D&st=2021-05-19T19%3A11%3A37Z&se=2021-05-20T03%3A21%3A37Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=eZl%2BcCWGLLYttlYKJojo%2BjKUcHO5az4qshj8aDIzmYg%3D&st=2021-05-19T19%3A11%3A37Z&se=2021-05-20T03%3A21%3A37Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=2od8LphALqlSus3ecvd5e95%2BTMvLayjfe3%2BV6qnkF1g%3D&st=2021-05-19T19%3A11%3A37Z&se=2021-05-20T03%3A21%3A37Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=40bsmQxuZO66LQ4g4a%2FupfdbosE%2FlXCo9o56AKF%2BRVc%3D&st=2021-05-19T19%3A11%3A37Z&se=2021-05-20T03%3A21%3A37Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=oiOrx1evIf0oX2M57w9%2BFMaI0b3BorfUSnrKD%2FJwrI8%3D&st=2021-05-19T19%3A11%3A37Z&se=2021-05-20T03%3A21%3A37Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_e5653443bc62c73b3418f0c71f7af29a68c0ea74ad941cc3f81d61c8c4a1656b_p.txt\"], [\"azureml-logs/65_job_prep-tvmps_e5653443bc62c73b3418f0c71f7af29a68c0ea74ad941cc3f81d61c8c4a1656b_p.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_e5653443bc62c73b3418f0c71f7af29a68c0ea74ad941cc3f81d61c8c4a1656b_p.txt\"], [\"logs/azureml/111_azureml.log\"]], \"run_duration\": \"0:10:13\", \"run_number\": \"3\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"2021-05-16 13:00:14,267|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2021-05-16 13:00:14,267|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2021-05-16 13:00:14,327|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2021-05-16 13:00:14,328|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2021-05-16 13:00:14,695|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f1417fbe040> for run source azureml.scriptrun\\n2021-05-16 13:00:14,696|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-16 13:00:14,696|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-16 13:00:14,697|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-16 13:00:14,732|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2021-05-16 13:00:14,733|azureml.core.authentication|DEBUG|Time to expire 1813920.266977 seconds\\n2021-05-16 13:00:14,733|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2021-05-16 13:00:14,733|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2021-05-16 13:00:14,764|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:14,764|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:14,765|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:14,765|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:14,765|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:14,765|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:14,765|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:14,806|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-05-16 13:00:14,806|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-05-16 13:00:14,874|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-05-16 13:00:14,874|azureml._SubmittedRun#model-logreg_1621169534_9756326b|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'a5ca8c3a-a582-4bb4-837b-e75594558db8', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-05-16 13:00:14,874|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-05-16 13:00:14,875|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2021-05-16 13:00:14,875|azureml.WorkerPool|DEBUG|[START]\\n2021-05-16 13:00:14,875|azureml.SendRunKillSignal|DEBUG|[START]\\n2021-05-16 13:00:14,875|azureml.RunStatusContext|DEBUG|[START]\\n2021-05-16 13:00:14,875|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunContextManager.RunStatusContext|DEBUG|[START]\\n2021-05-16 13:00:14,875|azureml.MetricsClient|DEBUG|[START]\\n2021-05-16 13:00:14,875|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2021-05-16 13:00:14,875|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2021-05-16 13:00:14,875|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2021-05-16 13:00:14,875|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/model-logreg_1621169534_9756326b/mounts/workspaceblobstore/azureml/model-logreg_1621169534_9756326b\\n2021-05-16 13:00:14,875|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-05-16 13:00:14,876|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/model-logreg_1621169534_9756326b/mounts/workspaceblobstore/azureml/model-logreg_1621169534_9756326b\\n2021-05-16 13:00:15,348|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-16 13:00:15,348|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-16 13:00:15,349|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-05-16 13:00:15,349|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:15,349|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:15,350|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:15,350|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:15,350|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:15,350|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:15,350|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:15,372|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-05-16 13:00:15,372|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-05-16 13:00:15,451|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-05-16 13:00:15,451|azureml._SubmittedRun#model-logreg_1621169534_9756326b|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'a5ca8c3a-a582-4bb4-837b-e75594558db8', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-05-16 13:00:15,452|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-05-16 13:00:15,452|azureml.WorkspaceClient.get_workspace_run-async:False|DEBUG|[START]\\n2021-05-16 13:00:15,452|azureml.WorkspaceClient|DEBUG|ClientBase: Calling get_workspace_run with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/runs/{runId}\\n2021-05-16 13:00:15,523|azureml.WorkspaceClient.get_workspace_run-async:False|DEBUG|[STOP]\\n2021-05-16 13:00:15,524|azureml.WorkspaceClient.get_by_id-async:False|DEBUG|[START]\\n2021-05-16 13:00:15,524|azureml.WorkspaceClient|DEBUG|ClientBase: Calling get_by_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}\\n2021-05-16 13:00:15,606|azureml.WorkspaceClient.get_by_id-async:False|DEBUG|[STOP]\\n2021-05-16 13:00:15,606|azureml.core.run|DEBUG|Available factories for run types {'azureml.scriptrun': <function ScriptRun._from_run_dto at 0x7f1417fbe040>}\\n2021-05-16 13:00:15,606|azureml.core.run|DEBUG|Initializing Run preprocessing_1620804387_12320a41 from type azureml.scriptrun\\n2021-05-16 13:00:15,608|azureml.ScriptRun#preprocessing_1620804387_12320a41|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '81d4648f-3f6e-4132-8615-eb36ee425972', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-05-16 13:00:15,608|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-05-16 13:00:15,609|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.list_metrics-async:True|DEBUG|[START]\\n2021-05-16 13:00:15,609|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _execute_with_base_arguments\\n2021-05-16 13:00:15,609|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling list_metrics with url /metric/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/runs/{runId}/list\\n2021-05-16 13:00:15,609|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.list_metrics|DEBUG|Using basic handler - no exception handling\\n2021-05-16 13:00:15,612|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.list_metrics-async:True|DEBUG|[STOP]\\n2021-05-16 13:00:15,612|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.list_metrics.WaitingTask|DEBUG|[START]\\n2021-05-16 13:00:15,612|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.list_metrics.WaitingTask|DEBUG|Awaiter is ApiPagination\\n2021-05-16 13:00:15,710|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.list_metrics.WaitingTask|DEBUG|[STOP]\\n2021-05-16 13:00:15,710|azureml._restclient.clientbase|DEBUG|Found continuation_token field in DTO\\n2021-05-16 13:00:15,710|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.get_full_fidelity-async:False|DEBUG|[START]\\n2021-05-16 13:00:15,710|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling get_full_fidelity with url /metric/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/runs/{runId}/full\\n2021-05-16 13:00:16,043|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.get_full_fidelity-async:False|DEBUG|[STOP]\\n2021-05-16 13:00:16,370|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-16 13:00:16,371|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-16 13:00:16,371|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-05-16 13:00:16,372|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:16,372|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:16,373|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:16,373|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:16,375|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:16,379|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:16,379|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:27,269|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-16 13:00:27,269|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-16 13:00:27,270|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-05-16 13:00:27,270|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:27,270|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:27,271|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:27,271|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:27,271|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:27,271|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:27,271|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 13:00:27,277|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[START]\\n2021-05-16 13:00:27,278|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling patch_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-05-16 13:00:27,443|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[STOP]\\n2021-05-16 13:00:44,713|azureml.core.authentication|DEBUG|Time to expire 1813890.286464 seconds\\n2021-05-16 13:01:14,703|azureml.core.authentication|DEBUG|Time to expire 1813860.296247 seconds\\n2021-05-16 13:01:44,704|azureml.core.authentication|DEBUG|Time to expire 1813830.29596 seconds\\n2021-05-16 13:02:01,955|azureml._SubmittedRun#model-logreg_1621169534_9756326b|INFO|complete is not setting status for submitted runs.\\n2021-05-16 13:02:01,955|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-05-16 13:02:01,955|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-05-16 13:02:01,956|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-16 13:02:01,956|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-05-16 13:02:01,956|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 13:02:01,956|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-05-16 13:02:01,956|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-05-16 13:02:01,956|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-05-16 13:02:01,956|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:01,956|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-05-16 13:02:01,957|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-16 13:02:01,957|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-05-16 13:02:01,957|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 13:02:01,957|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-05-16 13:02:01,957|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-05-16 13:02:01,957|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-05-16 13:02:01,957|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:01,957|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:01,957|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-05-16 13:02:01,958|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-05-16 13:02:02,036|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-05-16 13:02:02,037|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: [], excluding []\\n2021-05-16 13:02:02,037|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2021-05-16 13:02:02,325|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-05-16 13:02:02,325|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/model-logreg_1621169534_9756326b/mounts/workspaceblobstore/azureml/model-logreg_1621169534_9756326b\\n2021-05-16 13:02:02,325|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/model-logreg_1621169534_9756326b/mounts/workspaceblobstore/azureml/model-logreg_1621169534_9756326b to /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/model-logreg_1621169534_9756326b/mounts/workspaceblobstore/azureml/model-logreg_1621169534_9756326b\\n2021-05-16 13:02:02,325|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/model-logreg_1621169534_9756326b/mounts/workspaceblobstore/azureml/model-logreg_1621169534_9756326b\\n2021-05-16 13:02:02,325|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2021-05-16 13:02:02,325|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2021-05-16 13:02:02,326|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-05-16 13:02:02,326|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-05-16 13:02:02,326|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-16 13:02:02,326|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-05-16 13:02:02,326|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 13:02:02,326|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-05-16 13:02:02,326|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-05-16 13:02:02,326|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-05-16 13:02:02,326|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:02,326|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-05-16 13:02:02,327|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-16 13:02:02,327|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-05-16 13:02:02,327|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 13:02:02,327|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-05-16 13:02:02,327|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-05-16 13:02:02,327|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-05-16 13:02:02,327|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:02,327|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:02,327|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-05-16 13:02:02,327|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-05-16 13:02:03,142|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-05-16 13:02:03,142|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:03,148|azureml.MetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:03,148|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-05-16 13:02:03,148|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 13:02:03,148|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-05-16 13:02:03,148|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-05-16 13:02:03,149|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-05-16 13:02:03,149|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:03,149|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 13:02:03,149|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-05-16 13:02:03,149|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-05-16 13:02:03,149|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-05-16 13:02:03,149|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:03,149|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:03,149|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-05-16 13:02:03,149|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-05-16 13:02:03,230|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-05-16 13:02:03,230|azureml.RunStatusContext|DEBUG|[STOP]\\n2021-05-16 13:02:03,231|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-05-16 13:02:03,231|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 13:02:03,231|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-05-16 13:02:03,231|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-05-16 13:02:03,231|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-05-16 13:02:03,231|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:03,231|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 13:02:03,231|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-05-16 13:02:03,231|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-05-16 13:02:03,231|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-05-16 13:02:03,231|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:03,232|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:03,232|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-05-16 13:02:03,232|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-05-16 13:02:03,318|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-05-16 13:02:03,319|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-05-16 13:02:03,319|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 13:02:03,319|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-05-16 13:02:03,319|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-05-16 13:02:03,319|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-05-16 13:02:03,319|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:03,319|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 13:02:03,319|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-05-16 13:02:03,319|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-05-16 13:02:03,319|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-05-16 13:02:03,319|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:03,319|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:03,320|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-05-16 13:02:03,320|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-05-16 13:02:03,399|azureml._SubmittedRun#model-logreg_1621169534_9756326b.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-05-16 13:02:03,399|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-05-16 13:02:03,399|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-05-16 13:02:03,399|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-16 13:02:03,400|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-05-16 13:02:03,400|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 13:02:03,400|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-05-16 13:02:03,400|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-05-16 13:02:03,400|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-05-16 13:02:03,400|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:03,400|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-05-16 13:02:03,400|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-16 13:02:03,400|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-05-16 13:02:03,400|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 13:02:03,401|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-05-16 13:02:03,401|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-05-16 13:02:03,401|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-05-16 13:02:03,401|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:03,401|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-05-16 13:02:03,401|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-05-16 13:02:03,401|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-05-16 13:02:03,482|azureml.ScriptRun#preprocessing_1620804387_12320a41.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-05-16 13:02:03,482|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2021-05-16 13:02:03,482|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2021-05-16 13:02:03,483|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2021-05-16 13:02:03,483|azureml.WorkerPool|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.26.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'model-logreg_1621169534_9756326b',\n",
       " 'target': 'cluster-projet7',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-05-16T12:56:52.927453Z',\n",
       " 'endTimeUtc': '2021-05-16T13:02:29.757027Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'a5ca8c3a-a582-4bb4-837b-e75594558db8',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': 'd9db56c0-2808-4f18-8c01-1dde8e46b7e1'}, 'consumptionDetails': {'type': 'Reference'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'model-logreg.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--input-data',\n",
       "   'train-pre',\n",
       "   '--run-id',\n",
       "   'preprocessing_1620804387_12320a41'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'cluster-projet7',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'proj7-h',\n",
       "   'version': '6',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge', 'defaults'],\n",
       "     'dependencies': ['pip',\n",
       "      'pandas',\n",
       "      'scikit-learn',\n",
       "      'nltk',\n",
       "      'python=3.8',\n",
       "      'tensorflow',\n",
       "      'numpy=1.18.5',\n",
       "      'ipykernel',\n",
       "      'notebook',\n",
       "      'pyahocorasick',\n",
       "      'keras',\n",
       "      {'pip': ['azureml-core', 'azureml-dataset-runtime', 'contractions']}],\n",
       "     'name': 'azureml_ca6b2b150ca6091db30bfc50f017762f'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'dockerContext': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_e5653443bc62c73b3418f0c71f7af29a68c0ea74ad941cc3f81d61c8c4a1656b_p.txt': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/azureml-logs/55_azureml-execution-tvmps_e5653443bc62c73b3418f0c71f7af29a68c0ea74ad941cc3f81d61c8c4a1656b_p.txt?sv=2019-02-02&sr=b&sig=PxHW0JIztD%2BopXvtm6iELkTc%2FS5yF64u8PL7dVtZfZI%3D&st=2021-05-16T12%3A52%3A19Z&se=2021-05-16T21%3A02%3A19Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_e5653443bc62c73b3418f0c71f7af29a68c0ea74ad941cc3f81d61c8c4a1656b_p.txt': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/azureml-logs/65_job_prep-tvmps_e5653443bc62c73b3418f0c71f7af29a68c0ea74ad941cc3f81d61c8c4a1656b_p.txt?sv=2019-02-02&sr=b&sig=TOZyZSpgZk9q4hk8JxEnhsy6MFNTOxk7WlZmHa5VEg8%3D&st=2021-05-16T12%3A52%3A19Z&se=2021-05-16T21%3A02%3A19Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=5%2FF1%2B1IU59AdW0jXEQXvUTeFM9K85HvTjlEK7qK9JZw%3D&st=2021-05-16T12%3A52%3A19Z&se=2021-05-16T21%3A02%3A19Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_e5653443bc62c73b3418f0c71f7af29a68c0ea74ad941cc3f81d61c8c4a1656b_p.txt': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/azureml-logs/75_job_post-tvmps_e5653443bc62c73b3418f0c71f7af29a68c0ea74ad941cc3f81d61c8c4a1656b_p.txt?sv=2019-02-02&sr=b&sig=XBrbozTJM8RdHmTsZgekJ%2B0KJl0UJ467HFWr4DZ20LM%3D&st=2021-05-16T12%3A52%3A19Z&se=2021-05-16T21%3A02%3A19Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=Vaxn6Ig664DBmvcorOnfw%2FDJx6RzVOa3gaTprFBgcjs%3D&st=2021-05-16T12%3A52%3A19Z&se=2021-05-16T21%3A02%3A19Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=z%2FWch6ZrSbHO09nqsIIJKQijhENWyq1Rtpzq1Q7KnOA%3D&st=2021-05-16T12%3A52%3A19Z&se=2021-05-16T21%3A02%3A19Z&sp=r',\n",
       "  'logs/azureml/111_azureml.log': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/logs/azureml/111_azureml.log?sv=2019-02-02&sr=b&sig=6PfJ5MOku4hDpCmLPyTWzZFltzyT8T8IsTLnR4xGL2w%3D&st=2021-05-16T12%3A52%3A19Z&se=2021-05-16T21%3A02%3A19Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=rsrXY6Mgi%2Fse1JjaBxj3YOF2rulx%2B2y%2F7YZ1bzF5Cy0%3D&st=2021-05-16T12%3A52%3A19Z&se=2021-05-16T21%3A02%3A19Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=KWxm%2F9nEKdNJvMCruEnlwgL%2FnQEfbec4vJOdraW%2BLZg%3D&st=2021-05-16T12%3A52%3A19Z&se=2021-05-16T21%3A02%3A19Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=RkJ%2FznnijgX8utuiXT9SDn6b3FilO7j26P7M2cQXhoc%3D&st=2021-05-16T12%3A52%3A19Z&se=2021-05-16T21%3A02%3A19Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.model-logreg_1621169534_9756326b/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=pO3M%2FfNTc6dFS1G2su3Xxf%2FXNgLJf6dblXxnAf8qAbQ%3D&st=2021-05-16T12%3A52%3A19Z&se=2021-05-16T21%3A02%3A19Z&sp=r'},\n",
       " 'submittedBy': 'Axel Favreul'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory='lstm',\n",
    "                                script='model-logreg.py',\n",
    "                                arguments = ['--input-data', 'train-pre',\n",
    "                                            '--run-id', 'preprocessing_1620804387_12320a41'],\n",
    "                                environment=registered_env,\n",
    "                                compute_target=cluster_name) \n",
    "\n",
    "# submit the experiment\n",
    "experiment_name = 'model-logreg'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8f907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj7",
   "language": "python",
   "name": "proj7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
