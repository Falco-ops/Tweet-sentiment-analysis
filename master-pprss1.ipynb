{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "executed-ticket",
   "metadata": {},
   "source": [
    "## Connection to Azure ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "instant-polls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.26.0 to work with projet_7\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-maine",
   "metadata": {},
   "source": [
    "## Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "greek-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dirty-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-smoke",
   "metadata": {},
   "source": [
    "## Experiment folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tracked-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#experiment_folder = 'lstm-embedding'\n",
    "#os.makedirs(experiment_folder, exist_ok=True)\n",
    "#print(experiment_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-bankruptcy",
   "metadata": {},
   "source": [
    "## Define environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "straight-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pursuant-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment.from_conda_specification('proj7-h', 'env.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9f940bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = Environment.from_pip_requirements('proj7-1', 'lstm/requirements.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf0a2e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = Environment.from_existing_conda_environment(\"proj7-e\", 'proj7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "native-hearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proj7-h environment defined\n"
     ]
    }
   ],
   "source": [
    "print(env.name, 'environment defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "blind-worthy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"proj7-h\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"conda-forge\",\n",
       "                \"defaults\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"pip\",\n",
       "                \"pandas\",\n",
       "                \"scikit-learn\",\n",
       "                \"nltk\",\n",
       "                \"python=3.8\",\n",
       "                \"tensorflow\",\n",
       "                \"numpy=1.18.5\",\n",
       "                \"ipykernel\",\n",
       "                \"notebook\",\n",
       "                \"pyahocorasick\",\n",
       "                \"keras\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-core\",\n",
       "                        \"azureml-dataset-runtime\",\n",
       "                        \"contractions\"\n",
       "                    ]\n",
       "                }\n",
       "            ],\n",
       "            \"name\": \"azureml_ca6b2b150ca6091db30bfc50f017762f\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"7\"\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-politics",
   "metadata": {},
   "source": [
    "## Compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "auburn-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "standard-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "cluster_name = 'cluster-projet7'\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-distributor",
   "metadata": {},
   "source": [
    "## Script preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "precise-packing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lstm/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lstm/preprocessing.py\n",
    "print('print importing lib...')\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "from azureml.core import Dataset\n",
    "#import joblib\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import contractions\n",
    "\n",
    "print('lib imported...')\n",
    "# Get script arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n",
    "args = parser.parse_args()\n",
    "\n",
    "#set parameters\n",
    "dataset_name = args.training_dataset_id\n",
    "\n",
    "#get the experiment run context and workspace\n",
    "run = Run.get_context()\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "#loading data\n",
    "print(\"loading data...\")\n",
    "data = Dataset.get_by_name(ws, dataset_name).to_pandas_dataframe()\n",
    "\n",
    "#download stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#function for url. here for explanation https://regex101.com/r/NmVGOo/8\n",
    "def del_url(text):\n",
    "    return re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", text)\n",
    "\n",
    "#function for tweeter adress\n",
    "def del_tweet(text):\n",
    "    return re.sub('@[^\\s]+', ' ', text)\n",
    "\n",
    "#number\n",
    "def del_num(text):\n",
    "    return re.sub('[0-9]+', '', text)\n",
    "\n",
    "#repeating character >3\n",
    "def del_rep(text):\n",
    "    return re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
    "\n",
    "def contraction(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def stemmization(list):\n",
    "    porter = PorterStemmer()\n",
    "    list_stem=[]\n",
    "    for word in list:\n",
    "        list_stem.append(porter.stem(word))\n",
    "    return list_stem\n",
    "\n",
    "def filter_stopword(list):\n",
    "    list_f = [word for word in list if not word in stop_words]\n",
    "    return list_f\n",
    "\n",
    "# function for email\n",
    "def del_mail(text):\n",
    "    return re.sub('[^\\s]+@[^\\s]+', ' ', text)\n",
    "\n",
    "def preprocess(data, col):\n",
    "    #lower case\n",
    "    data[col] = data[col].str.lower()\n",
    "    #remove url (must come first before del tweet)\n",
    "    data[col] = data[col].apply(del_url)\n",
    "    #remove mail\n",
    "    data[col] = data[col].apply(del_mail)\n",
    "    #remove tweet adress\n",
    "    data[col] = data[col].apply(del_tweet)\n",
    "    #expand contraction and slang\n",
    "    data[col] = data[col].apply(contraction)\n",
    "    #removing punctuation. maketrans creates a table. third arguement=to remove\n",
    "    # function translate avec la table/map\n",
    "    map_punc = str.maketrans('','', string.punctuation)\n",
    "    data[col] = data[col].str.translate(map_punc)\n",
    "    #remove non ascii\n",
    "    data[col] = data[col].str.encode('ascii', 'ignore').str.decode('utf-8', 'ignore')\n",
    "    #remove number\n",
    "    data[col] = data[col].apply(del_num)\n",
    "    #remove repeating characters (eventually skip this to see difference)\n",
    "    data[col] = data[col].apply(del_rep)\n",
    "    #spelling/slang correction (very long)\n",
    "    #data[col] = data[col].apply(spelling)\n",
    "    \n",
    "    #text to sequence\n",
    "    data[col] = data[col].apply(text_to_word_sequence)\n",
    "    #stop words\n",
    "    data[col] = data[col].apply(filter_stopword)\n",
    "    #stemming\n",
    "    data[col] = data[col].apply(stemmization)\n",
    "    \n",
    "    return data\n",
    "\n",
    "print('start preprocess...')\n",
    "preprocess(data, 'text')\n",
    "\n",
    "# vocabulary size\n",
    "def get_vocab(data, col):\n",
    "    voca = Counter()\n",
    "    for x in data[col]:\n",
    "        voca.update(x)\n",
    "    vocab_low_freq=[]\n",
    "    vocab_low_freq = [w for w,c in voca.most_common() if c<3]\n",
    "    V = len(voca) - len(vocab_low_freq)\n",
    "    return V\n",
    "\n",
    "print('getting vocab size...')\n",
    "vocab_size = get_vocab(data, 'text')\n",
    "run.log('vocab_size', vocab_size)\n",
    "\n",
    "def seq_to_text(seq):\n",
    "    txt = ' '.join(seq)\n",
    "    return txt\n",
    "\n",
    "print('appying seq to text...')\n",
    "data['text'] = data['text'].apply(seq_to_text)\n",
    "\n",
    "# Save a sample of the data in the outputs folder (which gets uploaded automatically)\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "data.to_csv(\"train-pre.csv\", index=False, header=True)\n",
    "run.upload_file(name='outputs/train-pre.csv', path_or_stream='./train-pre.csv')\n",
    "\n",
    "\n",
    "run.complete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "veterinary-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "democratic-subscriber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414d4a54fcef45bb95bdb42a4a922840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/preprocessing_1621180841_b12833e2?wsid=/subscriptions/b9053cbf-be55-4e83-8c03-d6b0eb90cb5a/resourcegroups/Projet_7/workspaces/projet_7&tid=33e47288-d1e1-43e8-b65b-4ba7bfd37a9f\", \"run_id\": \"preprocessing_1621180841_b12833e2\", \"run_properties\": {\"run_id\": \"preprocessing_1621180841_b12833e2\", \"created_utc\": \"2021-05-16T16:00:44.127768Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"05522235-a897-4f48-982a-69bb74685e3e\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-05-16T16:10:35.429919Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_d213ae035300be9351a189effb08b6dc2e7052ce664d50a25f77a7001bb05b2f_p.txt\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/azureml-logs/55_azureml-execution-tvmps_d213ae035300be9351a189effb08b6dc2e7052ce664d50a25f77a7001bb05b2f_p.txt?sv=2019-02-02&sr=b&sig=6KcbxLGvzVuwOxUczfmR3pKH9vlvqyEiwQxSSuTpxXU%3D&st=2021-05-19T18%3A17%3A40Z&se=2021-05-20T02%3A27%3A40Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_d213ae035300be9351a189effb08b6dc2e7052ce664d50a25f77a7001bb05b2f_p.txt\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/azureml-logs/65_job_prep-tvmps_d213ae035300be9351a189effb08b6dc2e7052ce664d50a25f77a7001bb05b2f_p.txt?sv=2019-02-02&sr=b&sig=Ti96Le9WbpOPPOgtWyuq9xgeGjK9%2FOFJZS%2Fjpw%2BMr9U%3D&st=2021-05-19T18%3A17%3A40Z&se=2021-05-20T02%3A27%3A40Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=x7QbzWeUlx3rHjZ4rt0t4422MKYf9%2F3PdEYFIy7KYcI%3D&st=2021-05-19T18%3A17%3A40Z&se=2021-05-20T02%3A27%3A40Z&sp=r\", \"azureml-logs/75_job_post-tvmps_d213ae035300be9351a189effb08b6dc2e7052ce664d50a25f77a7001bb05b2f_p.txt\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/azureml-logs/75_job_post-tvmps_d213ae035300be9351a189effb08b6dc2e7052ce664d50a25f77a7001bb05b2f_p.txt?sv=2019-02-02&sr=b&sig=orNtioOQmCYjgCEPt3QwyoXhyH6Woied0GQeuam79pM%3D&st=2021-05-19T18%3A17%3A40Z&se=2021-05-20T02%3A27%3A40Z&sp=r\", \"azureml-logs/process_info.json\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=cacHWO6IaOa3pc7NnAaRDCq%2FFVAm%2FyHHpD0g6g9kPu4%3D&st=2021-05-19T18%3A17%3A40Z&se=2021-05-20T02%3A27%3A40Z&sp=r\", \"azureml-logs/process_status.json\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=Xb3msAuyC%2BGc%2BUjnpSv7zUhwVEZDKpftd1nilB0i0jk%3D&st=2021-05-19T18%3A17%3A40Z&se=2021-05-20T02%3A27%3A40Z&sp=r\", \"logs/azureml/112_azureml.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/logs/azureml/112_azureml.log?sv=2019-02-02&sr=b&sig=rF28bmfRwWjWsb91mjj4lu4srugzGvR6lrvGsbt25rw%3D&st=2021-05-19T18%3A17%3A40Z&se=2021-05-20T02%3A27%3A40Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=ss%2FB4yrz9A1bMSJnes8VOylvrlF0ZFrhHrtW8nMycM4%3D&st=2021-05-19T18%3A17%3A40Z&se=2021-05-20T02%3A27%3A40Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=KrRHkszRGgy98DJiz3ExhTRyc5Szs%2F2lfNTcLOttA4k%3D&st=2021-05-19T18%3A17%3A40Z&se=2021-05-20T02%3A27%3A40Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=2HVJ0j4wQn3mIygXu14%2Fqu1qbTTwqbMj2Ga5FjRQ%2FIc%3D&st=2021-05-19T18%3A17%3A40Z&se=2021-05-20T02%3A27%3A40Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=9VdRxX%2F%2BexHouCqN3RIHscGA0FIyTPtoqR1NGpWfdBE%3D&st=2021-05-19T18%3A17%3A40Z&se=2021-05-20T02%3A27%3A40Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_d213ae035300be9351a189effb08b6dc2e7052ce664d50a25f77a7001bb05b2f_p.txt\"], [\"azureml-logs/65_job_prep-tvmps_d213ae035300be9351a189effb08b6dc2e7052ce664d50a25f77a7001bb05b2f_p.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_d213ae035300be9351a189effb08b6dc2e7052ce664d50a25f77a7001bb05b2f_p.txt\"], [\"logs/azureml/112_azureml.log\"]], \"run_duration\": \"0:09:51\", \"run_number\": \"24\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"vocab_size\", \"run_id\": \"preprocessing_1621180841_b12833e2\", \"categories\": [0], \"series\": [{\"data\": [56793]}]}], \"run_logs\": \"2021-05-16 16:05:21,980|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2021-05-16 16:05:21,981|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2021-05-16 16:05:22,065|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2021-05-16 16:05:22,065|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2021-05-16 16:05:22,490|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f612e00f040> for run source azureml.scriptrun\\n2021-05-16 16:05:22,492|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-16 16:05:22,492|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-16 16:05:22,493|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-16 16:05:22,528|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2021-05-16 16:05:22,528|azureml.core.authentication|DEBUG|Time to expire 1814121.471035 seconds\\n2021-05-16 16:05:22,529|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2021-05-16 16:05:22,529|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2021-05-16 16:05:22,565|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:22,565|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:22,566|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:22,566|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:22,566|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:22,566|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:22,566|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:22,615|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-05-16 16:05:22,615|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-05-16 16:05:22,699|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-05-16 16:05:22,700|azureml._SubmittedRun#preprocessing_1621180841_b12833e2|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '05522235-a897-4f48-982a-69bb74685e3e', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-05-16 16:05:22,700|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-05-16 16:05:22,700|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2021-05-16 16:05:22,700|azureml.WorkerPool|DEBUG|[START]\\n2021-05-16 16:05:22,701|azureml.SendRunKillSignal|DEBUG|[START]\\n2021-05-16 16:05:22,701|azureml.RunStatusContext|DEBUG|[START]\\n2021-05-16 16:05:22,701|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunContextManager.RunStatusContext|DEBUG|[START]\\n2021-05-16 16:05:22,701|azureml.MetricsClient|DEBUG|[START]\\n2021-05-16 16:05:22,701|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2021-05-16 16:05:22,701|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2021-05-16 16:05:22,701|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2021-05-16 16:05:22,701|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1621180841_b12833e2/mounts/workspaceblobstore/azureml/preprocessing_1621180841_b12833e2\\n2021-05-16 16:05:22,701|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-05-16 16:05:22,701|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1621180841_b12833e2/mounts/workspaceblobstore/azureml/preprocessing_1621180841_b12833e2\\n2021-05-16 16:05:52,494|azureml.core.authentication|DEBUG|Time to expire 1814091.506003 seconds\\n2021-05-16 16:05:57,337|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-16 16:05:57,337|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-16 16:05:57,338|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-05-16 16:05:57,338|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:57,338|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:57,339|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:57,339|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:57,339|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:57,339|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:57,339|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:57,361|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-05-16 16:05:57,362|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-05-16 16:05:57,448|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-05-16 16:05:57,449|azureml._SubmittedRun#preprocessing_1621180841_b12833e2|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '05522235-a897-4f48-982a-69bb74685e3e', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-05-16 16:05:57,449|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-05-16 16:05:57,827|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-16 16:05:57,828|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-16 16:05:57,828|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-05-16 16:05:57,829|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:57,830|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:57,831|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:57,831|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:57,833|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:57,838|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:05:57,839|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:06:10,049|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-16 16:06:10,049|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-16 16:06:10,050|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-05-16 16:06:10,050|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:06:10,050|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:06:10,051|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:06:10,051|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:06:10,051|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:06:10,051|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:06:10,051|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-16 16:06:10,061|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[START]\\n2021-05-16 16:06:10,061|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling patch_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-05-16 16:06:10,202|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[STOP]\\n2021-05-16 16:06:22,509|azureml.core.authentication|DEBUG|Time to expire 1814061.490423 seconds\\n2021-05-16 16:06:52,520|azureml.core.authentication|DEBUG|Time to expire 1814031.480003 seconds\\n2021-05-16 16:07:22,530|azureml.core.authentication|DEBUG|Time to expire 1814001.469462 seconds\\n2021-05-16 16:07:52,536|azureml.core.authentication|DEBUG|Time to expire 1813971.463765 seconds\\n2021-05-16 16:08:22,538|azureml.core.authentication|DEBUG|Time to expire 1813941.461384 seconds\\n2021-05-16 16:08:52,546|azureml.core.authentication|DEBUG|Time to expire 1813911.453404 seconds\\n2021-05-16 16:09:22,551|azureml.core.authentication|DEBUG|Time to expire 1813881.44807 seconds\\n2021-05-16 16:09:52,557|azureml.core.authentication|DEBUG|Time to expire 1813851.442716 seconds\\n2021-05-16 16:10:05,943|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-05-16 16:10:05,943|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-16 16:10:05,944|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-05-16 16:10:06,966|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-05-16 16:10:06,966|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-05-16 16:10:06,966|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 1.\\n2021-05-16 16:10:06,966|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-05-16 16:10:06,966|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-05-16 16:10:06,967|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-05-16 16:10:06,967|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 1 values.\\n2021-05-16 16:10:06,967|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-05-16 16:10:06,967|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-05-16 16:10:06,967|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-05-16 16:10:06,967|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2021-05-16 16:10:06,968|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-05-16 16:10:06,968|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-05-16 16:10:06,968|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-05-16 16:10:06,971|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-05-16 16:10:06,972|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-05-16 16:10:06,972|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-05-16 16:10:06,972|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-05-16 16:10:06,972|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2021-05-16 16:10:06,972|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-05-16 16:10:07,230|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-05-16 16:10:10,985|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.ArtifactsClient|DEBUG|Called upload_artifact\\n2021-05-16 16:10:10,985|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.ArtifactsClient|DEBUG|Uploading path artifact\\n2021-05-16 16:10:10,986|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-05-16 16:10:10,986|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-05-16 16:10:11,336|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-05-16 16:10:11,337|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2021-05-16 16:10:13,517|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.preprocessing_1621180841_b12833e2/outputs/sample-pre.csv with size 51345801, file size 51345801.\\n2021-05-16 16:10:13,517|azureml._SubmittedRun#preprocessing_1621180841_b12833e2|INFO|complete is not setting status for submitted runs.\\n2021-05-16 16:10:13,517|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-05-16 16:10:13,517|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-05-16 16:10:13,518|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-16 16:10:13,518|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-05-16 16:10:13,518|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 16:10:13,518|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-05-16 16:10:13,518|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-05-16 16:10:13,518|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-05-16 16:10:13,518|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 16:10:13,518|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 16:10:13,518|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-05-16 16:10:13,519|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2021-05-16 16:10:13,519|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2021-05-16 16:10:13,519|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2021-05-16 16:10:13,519|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2021-05-16 16:10:13,519|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-05-16 16:10:13,519|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 16:10:13,519|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-05-16 16:10:13,519|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-05-16 16:10:13,519|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-05-16 16:10:13,608|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-05-16 16:10:13,609|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: [], excluding []\\n2021-05-16 16:10:13,609|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2021-05-16 16:10:13,780|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-05-16 16:10:13,780|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1621180841_b12833e2/mounts/workspaceblobstore/azureml/preprocessing_1621180841_b12833e2\\n2021-05-16 16:10:13,780|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1621180841_b12833e2/mounts/workspaceblobstore/azureml/preprocessing_1621180841_b12833e2 to /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1621180841_b12833e2/mounts/workspaceblobstore/azureml/preprocessing_1621180841_b12833e2\\n2021-05-16 16:10:13,780|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1621180841_b12833e2/mounts/workspaceblobstore/azureml/preprocessing_1621180841_b12833e2\\n2021-05-16 16:10:13,780|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2021-05-16 16:10:13,781|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2021-05-16 16:10:13,781|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-05-16 16:10:13,781|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-05-16 16:10:13,781|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-16 16:10:13,781|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-05-16 16:10:13,781|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 16:10:13,781|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-05-16 16:10:13,781|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-05-16 16:10:13,781|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-05-16 16:10:13,782|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 16:10:13,782|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-05-16 16:10:13,782|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-16 16:10:13,782|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-05-16 16:10:13,782|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 16:10:13,782|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-05-16 16:10:13,782|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-05-16 16:10:13,782|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-05-16 16:10:13,782|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 16:10:13,782|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-05-16 16:10:13,782|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-05-16 16:10:13,782|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-05-16 16:10:13,861|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-05-16 16:10:13,862|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient|DEBUG|[STOP]\\n2021-05-16 16:10:13,866|azureml.MetricsClient|DEBUG|[STOP]\\n2021-05-16 16:10:13,866|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-05-16 16:10:13,867|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 16:10:13,867|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-05-16 16:10:13,867|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-05-16 16:10:13,867|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-05-16 16:10:13,867|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 16:10:13,867|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 16:10:13,867|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-05-16 16:10:13,867|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-05-16 16:10:13,867|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-05-16 16:10:13,867|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 16:10:13,867|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-05-16 16:10:13,868|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-05-16 16:10:13,868|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-05-16 16:10:13,963|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-05-16 16:10:13,963|azureml.RunStatusContext|DEBUG|[STOP]\\n2021-05-16 16:10:13,963|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-05-16 16:10:13,963|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 16:10:13,963|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-05-16 16:10:13,964|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-05-16 16:10:13,964|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-05-16 16:10:13,964|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 16:10:13,964|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 16:10:13,964|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-05-16 16:10:13,964|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-05-16 16:10:13,964|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-05-16 16:10:13,964|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 16:10:13,964|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-05-16 16:10:13,964|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-05-16 16:10:13,964|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-05-16 16:10:14,048|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-05-16 16:10:14,049|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-05-16 16:10:14,049|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 16:10:14,049|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-05-16 16:10:14,049|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-05-16 16:10:14,049|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-05-16 16:10:14,049|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 16:10:14,049|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-16 16:10:14,049|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-05-16 16:10:14,049|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-05-16 16:10:14,049|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-05-16 16:10:14,049|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-16 16:10:14,050|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-05-16 16:10:14,050|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-05-16 16:10:14,050|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-05-16 16:10:14,142|azureml._SubmittedRun#preprocessing_1621180841_b12833e2.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-05-16 16:10:14,143|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2021-05-16 16:10:14,143|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2021-05-16 16:10:14,143|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2021-05-16 16:10:14,143|azureml.WorkerPool|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.26.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'preprocessing_1621180841_b12833e2',\n",
       " 'target': 'cluster-projet7',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-05-16T16:04:34.027998Z',\n",
       " 'endTimeUtc': '2021-05-16T16:10:35.429919Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': '05522235-a897-4f48-982a-69bb74685e3e',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '05c73edc-44c7-449a-a368-d886a0feda0e'}, 'consumptionDetails': {'type': 'Reference'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'preprocessing.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--input-data', 'train'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'cluster-projet7',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'proj7-h',\n",
       "   'version': '7',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge', 'defaults'],\n",
       "     'dependencies': ['pip',\n",
       "      'pandas',\n",
       "      'scikit-learn',\n",
       "      'nltk',\n",
       "      'python=3.8',\n",
       "      'tensorflow',\n",
       "      'numpy=1.18.5',\n",
       "      'ipykernel',\n",
       "      'notebook',\n",
       "      'pyahocorasick',\n",
       "      'keras',\n",
       "      {'pip': ['azureml-core', 'azureml-dataset-runtime', 'contractions']}],\n",
       "     'name': 'azureml_ca6b2b150ca6091db30bfc50f017762f'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'dockerContext': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_d213ae035300be9351a189effb08b6dc2e7052ce664d50a25f77a7001bb05b2f_p.txt': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/azureml-logs/55_azureml-execution-tvmps_d213ae035300be9351a189effb08b6dc2e7052ce664d50a25f77a7001bb05b2f_p.txt?sv=2019-02-02&sr=b&sig=TEg4J7yTAkDKocIJpqZ4uRBZRewkBo0PM9sLz1QELjc%3D&st=2021-05-16T16%3A00%3A29Z&se=2021-05-17T00%3A10%3A29Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_d213ae035300be9351a189effb08b6dc2e7052ce664d50a25f77a7001bb05b2f_p.txt': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/azureml-logs/65_job_prep-tvmps_d213ae035300be9351a189effb08b6dc2e7052ce664d50a25f77a7001bb05b2f_p.txt?sv=2019-02-02&sr=b&sig=ZmJ69vHVAMPBLLdeGbtZmR6gUu3ckwQYI7SXrN%2Fo8BM%3D&st=2021-05-16T16%3A00%3A29Z&se=2021-05-17T00%3A10%3A29Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=P%2FMjG%2BA20y%2F081h257Pn%2B8OuqExR6fYd68ecQDhNxKg%3D&st=2021-05-16T16%3A00%3A29Z&se=2021-05-17T00%3A10%3A29Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_d213ae035300be9351a189effb08b6dc2e7052ce664d50a25f77a7001bb05b2f_p.txt': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/azureml-logs/75_job_post-tvmps_d213ae035300be9351a189effb08b6dc2e7052ce664d50a25f77a7001bb05b2f_p.txt?sv=2019-02-02&sr=b&sig=zqv5e7IUHyG8kl6cA6FYhSIcvCWdEoJVvbmlFXbGGKo%3D&st=2021-05-16T16%3A00%3A29Z&se=2021-05-17T00%3A10%3A29Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=tHLB0VLkMp05vlbwlR69wJQhaTAhwJGmFnOGWFbTCg0%3D&st=2021-05-16T16%3A00%3A29Z&se=2021-05-17T00%3A10%3A29Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=WRParjpuhpt2DaIEWRjGUUqpfaVUiaxgWmD1hVo1jK4%3D&st=2021-05-16T16%3A00%3A29Z&se=2021-05-17T00%3A10%3A29Z&sp=r',\n",
       "  'logs/azureml/112_azureml.log': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/logs/azureml/112_azureml.log?sv=2019-02-02&sr=b&sig=Z%2FtjZUKOcbKeuvvgvBabp2lF6YZUjpvpDtS%2BlCQ%2B7Ww%3D&st=2021-05-16T16%3A00%3A29Z&se=2021-05-17T00%3A10%3A29Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=QVjNKa9VsQqD%2B0Y0rNYiE8JlSczVjlViIJXWXHzID4A%3D&st=2021-05-16T16%3A00%3A29Z&se=2021-05-17T00%3A10%3A29Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=ZGFwlRORZ%2FBJYohd7sZSu5dfxWlHG7umhaFTa1vJ40g%3D&st=2021-05-16T16%3A00%3A29Z&se=2021-05-17T00%3A10%3A29Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=UDo8vqxKxDzEgDOBoxFMGGLZVqFUNxFSJ3bGh5nfXbU%3D&st=2021-05-16T16%3A00%3A29Z&se=2021-05-17T00%3A10%3A29Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.preprocessing_1621180841_b12833e2/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=s8jT%2BGZFYbTyZmvSxFaX5TbpMcwpXpajtDD6lgA%2BUp8%3D&st=2021-05-16T16%3A00%3A30Z&se=2021-05-17T00%3A10%3A30Z&sp=r'},\n",
       " 'submittedBy': 'Axel Favreul'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the registered environment\n",
    "registered_env = Environment.get(ws, 'proj7-h')\n",
    "\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory='lstm',\n",
    "                                script='preprocessing.py',\n",
    "                                arguments = ['--input-data', 'train'],\n",
    "                                environment=registered_env,\n",
    "                                compute_target=cluster_name) \n",
    "\n",
    "# submit the experiment\n",
    "experiment_name = 'preprocessing'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a37fe85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size 6963\n"
     ]
    }
   ],
   "source": [
    "metrics = run.get_metrics()\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3c9807a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml-logs/55_azureml-execution-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt\n",
      "azureml-logs/65_job_prep-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt\n",
      "azureml-logs/70_driver_log.txt\n",
      "azureml-logs/75_job_post-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt\n",
      "azureml-logs/process_info.json\n",
      "azureml-logs/process_status.json\n",
      "logs/azureml/111_azureml.log\n",
      "logs/azureml/dataprep/backgroundProcess.log\n",
      "logs/azureml/dataprep/backgroundProcess_Telemetry.log\n",
      "logs/azureml/job_prep_azureml.log\n",
      "logs/azureml/job_release_azureml.log\n",
      "outputs/sample-pre.csv\n"
     ]
    }
   ],
   "source": [
    "for file in run.get_file_names():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97c3dd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'preprocessing_1620386671_6f8c3935',\n",
       " 'target': 'cluster-projet7',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-05-07T11:27:29.792364Z',\n",
       " 'endTimeUtc': '2021-05-07T11:29:49.302828Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'db65c98b-ac29-48d3-aa80-b630b55fbe6f',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '8d7b3d11-ae66-4cc3-a146-8fdcb3836526'}, 'consumptionDetails': {'type': 'Reference'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'preprocessing.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--input-data', 'sample'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'cluster-projet7',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'proj7-h',\n",
       "   'version': '6',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge', 'defaults'],\n",
       "     'dependencies': ['pip',\n",
       "      'pandas',\n",
       "      'scikit-learn',\n",
       "      'nltk',\n",
       "      'python=3.8',\n",
       "      'tensorflow',\n",
       "      'numpy=1.18.5',\n",
       "      'ipykernel',\n",
       "      'notebook',\n",
       "      'pyahocorasick',\n",
       "      'keras',\n",
       "      {'pip': ['azureml-core', 'azureml-dataset-runtime', 'contractions']}],\n",
       "     'name': 'azureml_ca6b2b150ca6091db30bfc50f017762f'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt': '2021-05-07T11:27:33Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore\\n2021-05-07T11:27:34Z Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\\n. Please ignore this if the GPUs don\\'t utilize NVIDIA® NVLink® switches.\\n2021-05-07T11:27:35Z Starting output-watcher...\\n2021-05-07T11:27:35Z IsDedicatedCompute == False, starting polling for Low-Pri Preemption\\n2021-05-07T11:27:35Z Executing \\'Copy ACR Details file\\' on 10.0.0.4\\n2021-05-07T11:27:35Z Copy ACR Details file succeeded on 10.0.0.4. Output: \\n>>>   \\n>>>   \\nLogin Succeeded\\nUsing default tag: latest\\nlatest: Pulling from azureml/azureml_a66eb09a2050c837952a91674b3559a2\\n4007a89234b4: Pulling fs layer\\n5dfa26c6b9c9: Pulling fs layer\\n0ba7bf18aa40: Pulling fs layer\\n4c6ec688ebe3: Pulling fs layer\\n574f361512d6: Pulling fs layer\\ndb4d1e2d7079: Pulling fs layer\\ne544ee0f522d: Pulling fs layer\\nc655136086be: Pulling fs layer\\n2ec37f44090c: Pulling fs layer\\n5fba3bd4a2c4: Pulling fs layer\\n7e0ea9d0a1ab: Pulling fs layer\\nda005f826951: Pulling fs layer\\n57f294f72a88: Pulling fs layer\\ne3ede356498e: Pulling fs layer\\nf24dc7ff0720: Pulling fs layer\\n9a886be5395d: Pulling fs layer\\n2c0244034627: Pulling fs layer\\nb54f421200a5: Pulling fs layer\\ndc6a051220f1: Pulling fs layer\\n68cf1502df85: Pulling fs layer\\n7c26c57066b7: Pulling fs layer\\nda005f826951: Waiting\\n57f294f72a88: Waiting\\ne3ede356498e: Waiting\\nf24dc7ff0720: Waiting\\n9a886be5395d: Waiting\\ne544ee0f522d: Waiting\\nc655136086be: Waiting\\n2c0244034627: Waiting\\n2ec37f44090c: Waiting\\n4c6ec688ebe3: Waiting\\n5fba3bd4a2c4: Waiting\\n574f361512d6: Waiting\\ndb4d1e2d7079: Waiting\\n7e0ea9d0a1ab: Waiting\\ndc6a051220f1: Waiting\\nb54f421200a5: Waiting\\n68cf1502df85: Waiting\\n7c26c57066b7: Waiting\\n5dfa26c6b9c9: Verifying Checksum\\n5dfa26c6b9c9: Download complete\\n0ba7bf18aa40: Verifying Checksum\\n0ba7bf18aa40: Download complete\\n4c6ec688ebe3: Verifying Checksum\\n4c6ec688ebe3: Download complete\\n4007a89234b4: Verifying Checksum\\n4007a89234b4: Download complete\\ne544ee0f522d: Verifying Checksum\\ne544ee0f522d: Download complete\\ndb4d1e2d7079: Download complete\\n574f361512d6: Verifying Checksum\\n574f361512d6: Download complete\\n4007a89234b4: Pull complete\\nc655136086be: Verifying Checksum\\nc655136086be: Download complete\\n5dfa26c6b9c9: Pull complete\\n7e0ea9d0a1ab: Verifying Checksum\\n7e0ea9d0a1ab: Download complete\\n0ba7bf18aa40: Pull complete\\nda005f826951: Download complete\\n5fba3bd4a2c4: Verifying Checksum\\n5fba3bd4a2c4: Download complete\\n57f294f72a88: Verifying Checksum\\n57f294f72a88: Download complete\\ne3ede356498e: Verifying Checksum\\ne3ede356498e: Download complete\\nf24dc7ff0720: Download complete\\n4c6ec688ebe3: Pull complete\\n9a886be5395d: Download complete\\nb54f421200a5: Verifying Checksum\\nb54f421200a5: Download complete\\n2ec37f44090c: Verifying Checksum\\n2ec37f44090c: Download complete\\ndc6a051220f1: Download complete\\n68cf1502df85: Verifying Checksum\\n68cf1502df85: Download complete\\n7c26c57066b7: Verifying Checksum\\n7c26c57066b7: Download complete\\n574f361512d6: Pull complete\\ndb4d1e2d7079: Pull complete\\n2c0244034627: Verifying Checksum\\n2c0244034627: Download complete\\ne544ee0f522d: Pull complete\\nc655136086be: Pull complete\\n2ec37f44090c: Pull complete\\n5fba3bd4a2c4: Pull complete\\n7e0ea9d0a1ab: Pull complete\\nda005f826951: Pull complete\\n57f294f72a88: Pull complete\\ne3ede356498e: Pull complete\\nf24dc7ff0720: Pull complete\\n9a886be5395d: Pull complete\\n2c0244034627: Pull complete\\nb54f421200a5: Pull complete\\ndc6a051220f1: Pull complete\\n68cf1502df85: Pull complete\\n7c26c57066b7: Pull complete\\nDigest: sha256:a9414e65fb3e3ae7accbacb87d30d82a3377c63b1b5c39e7609123d35a8c2b5b\\nStatus: Downloaded newer image for 38d02f2005824c85859d3a5c11c9a143.azurecr.io/azureml/azureml_a66eb09a2050c837952a91674b3559a2:latest\\n38d02f2005824c85859d3a5c11c9a143.azurecr.io/azureml/azureml_a66eb09a2050c837952a91674b3559a2:latest\\n2021-05-07T11:28:08Z Check if container preprocessing_1620386671_6f8c3935 already exist exited with 0, \\n\\n4f7c72c5e304d59589ab6f20da72bfa2875a3d9a119cea90fcc8492bcb407c7c\\n2021-05-07T11:28:24Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \\n2021-05-07T11:28:24Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-d0aae475bca74718f296ba48e0cc1c9b-cb6d4eeac0853290-01 -sshRequired=false] \\n2021/05/07 11:28:24 Starting App Insight Logger for task:  containerSetup\\n2021/05/07 11:28:24 Version: 3.0.01576.0004 Branch: .SourceBranch Commit: 5216581\\n2021/05/07 11:28:24 Entered ContainerSetupTask - Preparing infiniband\\n2021/05/07 11:28:24 Starting infiniband setup\\n2021/05/07 11:28:24 Python Version found is Python 3.8.8\\n\\n2021/05/07 11:28:24 Returning Python Version as 3.8\\n2021/05/07 11:28:24 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\\n2021/05/07 11:28:24 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\\n2021-05-07T11:28:24Z VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\\n2021/05/07 11:28:24 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\\n2021/05/07 11:28:24 Not setting up Infiniband in Container\\n2021/05/07 11:28:24 Not setting up Infiniband in Container\\n2021-05-07T11:28:24Z Not setting up Infiniband in Container\\n2021/05/07 11:28:24 Python Version found is Python 3.8.8\\n\\n2021/05/07 11:28:24 Returning Python Version as 3.8\\n2021/05/07 11:28:24 sshd inside container not required for job, skipping setup.\\n2021/05/07 11:28:24 All App Insights Logs was send successfully\\n2021/05/07 11:28:24 App Insight Client has already been closed\\n2021/05/07 11:28:24 Not exporting to RunHistory as the exporter is either stopped or there is no data.\\nStopped: false\\nOriginalData: 1\\nFilteredData: 0.\\n2021-05-07T11:28:24Z Starting docker container succeeded.\\n2021-05-07T11:28:32Z Job environment preparation succeeded on 10.0.0.4. Output: \\n>>>   2021/05/07 11:27:31 Starting App Insight Logger for task:  prepareJobEnvironment\\n>>>   2021/05/07 11:27:31 Version: 3.0.01576.0004 Branch: .SourceBranch Commit: 5216581\\n>>>   2021/05/07 11:27:31 runtime.GOOS linux\\n>>>   2021/05/07 11:27:31 Checking if \\'/tmp\\' exists\\n>>>   2021/05/07 11:27:31 Reading dyanamic configs\\n>>>   2021/05/07 11:27:31 Container sas url: https://baiscriptswesteuropeprod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=9UBH7ig8b9NIeIkNQpNxDmP7wUMtSqFoIE5AY22cheE%3D\\n>>>   2021/05/07 11:27:31 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables: no such file or directory\\n>>>   2021/05/07 11:27:31 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installer on host: false. Is Azsecpack enabled: false,\\n>>>   2021/05/07 11:27:31 Starting Azsecpack installation on machine: bc688c58e69a48ee923c00839604b357000000#33e47288-d1e1-43e8-b65b-4ba7bfd37a9f#b9053cbf-be55-4e83-8c03-d6b0eb90cb5a#projet_7#projet_7#cluster-projet7\\n>>>   2021/05/07 11:27:31 Is Azsecpack enabled: false, GetDisableVsatlsscan: true\\n>>>   2021/05/07 11:27:31 Turning off azsecpack, if it is already running\\n>>>   2021/05/07 11:27:31 [doTurnOffAzsecpack] output:Unit mdsd.service could not be found.\\n>>>   ,err:exit status 1.\\n>>>   2021/05/07 11:27:31 OS patching disabled by dynamic configs. Skipping.\\n>>>   2021/05/07 11:27:31 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\\n>>>   2021/05/07 11:27:31 Start to getting gpu count by running nvidia-smi command\\n>>>   2021/05/07 11:27:31 GPU : GPU 0: Tesla K80 (UUID: GPU-86853283-a7d7-86e0-d63f-0d85e158969a)\\n>>>   2021/05/07 11:27:31 GPU count found on the node: 1\\n>>>   2021/05/07 11:27:31 Mellanox Inbox drivers found (implying presence of SR-IOV)?: false\\n>>>   2021/05/07 11:27:31 Disabling IB for NCCL.\\n>>>   2021/05/07 11:27:31 AMLComputeXDSEndpoint:  https://westeurope-prodk8ds.batchai.core.windows.net\\n>>>   2021/05/07 11:27:31 AMLComputeXDSApiVersion:  2018-02-01\\n>>>   2021/05/07 11:27:31 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/config\\n>>>   2021/05/07 11:27:31 This is not a aml-workstation (compute instance), current offer type: amlcompute. Starting identity responder as part of prepareJobEnvironment.\\n>>>   2021/05/07 11:27:31 Starting identity responder.\\n>>>   2021/05/07 11:27:31 Starting identity responder.\\n>>>   2021/05/07 11:27:31 Failed to open file /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/config/.batchai.IdentityResponder.envlist: open /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/config/.batchai.IdentityResponder.envlist: no such file or directory\\n>>>   2021/05/07 11:27:31 Logfile used for identity responder: /mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/IdentityResponderLog-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt\\n>>>   2021/05/07 11:27:31 Logfile used for identity responder: /mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/IdentityResponderLog-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt\\n>>>   2021/05/07 11:27:31 Started Identity Responder for job.\\n>>>   2021/05/07 11:27:31 Started Identity Responder for job.\\n>>>   2021/05/07 11:27:31 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/wd\\n>>>   2021/05/07 11:27:31 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/shared\\n>>>   2021/05/07 11:27:31 From the policy service, the filtering patterns is: , data store is \\n>>>   2021/05/07 11:27:31 Mounting job level file systems\\n>>>   2021/05/07 11:27:31 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts\\n>>>   2021/05/07 11:27:31 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/config/.amlcompute.datastorecredentials\\n>>>   2021/05/07 11:27:31 Datastore credentials file not found, skipping.\\n>>>   2021/05/07 11:27:31 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/config/.master.runtimesastokens\\n>>>   2021/05/07 11:27:31 Runtime sas tokens file not found, skipping.\\n>>>   2021/05/07 11:27:31 No NFS configured\\n>>>   2021/05/07 11:27:31 No Azure File Shares configured\\n>>>   2021/05/07 11:27:31 Mounting blob file systems\\n>>>   2021/05/07 11:27:31 Blobfuse runtime version 1.3.6\\n>>>   2021/05/07 11:27:31 Mounting azureml-blobstore-38d02f20-0582-4c85-859d-3a5c11c9a143 container from stockageprojet7opcr account at /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore\\n>>>   2021/05/07 11:27:31 Using Compute Identity to authenticate Blobfuse: false.\\n>>>   2021/05/07 11:27:31 Using Compute Identity to authenticate Blobfuse: false.\\n>>>   2021/05/07 11:27:31 Blobfuse cache size set to 316318 MB.\\n>>>   2021/05/07 11:27:31 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=316318 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\\n>>>   2021/05/07 11:27:32 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore\\n>>>   2021/05/07 11:27:34 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore\\n>>>   2021/05/07 11:27:34 Successfully mounted azureml-blobstore-38d02f20-0582-4c85-859d-3a5c11c9a143 container from stockageprojet7opcr account at /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore\\n>>>   2021/05/07 11:27:34 No unmanaged file systems configured\\n>>>   2021/05/07 11:27:34 Start to getting gpu count by running nvidia-smi command\\n>>>   2021/05/07 11:27:34 GPU : GPU 0: Tesla K80 (UUID: GPU-86853283-a7d7-86e0-d63f-0d85e158969a)\\n>>>   2021/05/07 11:27:34 Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\\n>>>   . Please ignore this if the GPUs don\\'t utilize NVIDIA® NVLink® switches.\\n>>>   2021/05/07 11:27:34 Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\\n>>>   . Please ignore this if the GPUs don\\'t utilize NVIDIA® NVLink® switches.\\n>>>   2021/05/07 11:27:34 From the policy service, the filtering patterns is: , data store is \\n>>>   2021/05/07 11:27:34 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935/azureml_compute_logs\\n>>>   2021/05/07 11:27:34 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935/logs\\n>>>   2021/05/07 11:27:34 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935/outputs\\n>>>   2021/05/07 11:27:35 Starting output-watcher...\\n>>>   2021/05/07 11:27:35 Single file input dataset is enabled.\\n>>>   2021/05/07 11:27:35 Start to pulling docker image: 38d02f2005824c85859d3a5c11c9a143.azurecr.io/azureml/azureml_a66eb09a2050c837952a91674b3559a2\\n>>>   2021/05/07 11:27:35 Start pull docker image: 38d02f2005824c85859d3a5c11c9a143.azurecr.io\\n>>>   2021/05/07 11:27:35 Getting credentials for image 38d02f2005824c85859d3a5c11c9a143.azurecr.io/azureml/azureml_a66eb09a2050c837952a91674b3559a2 with url 38d02f2005824c85859d3a5c11c9a143.azurecr.io\\n>>>   2021/05/07 11:27:35 Container registry is ACR.\\n>>>   2021/05/07 11:27:35 Skip getting ACR Credentials from Identity and will be getting it from EMS\\n>>>   2021/05/07 11:27:35 Getting ACR Credentials from EMS for environment proj7-h:6\\n>>>   2021/05/07 11:27:35 Requesting XDS for registry details.\\n>>>   2021/05/07 11:27:35 Attempt 1 of http call to https://westeurope-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/b9053cbf-be55-4e83-8c03-d6b0eb90cb5a/resourceGroups/projet_7/workspaces/projet_7/clusters/cluster-projet7/nodes/tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p?api-version=2018-02-01\\n>>>   2021/05/07 11:27:35 Got container registry details from credentials service for registry address: 38d02f2005824c85859d3a5c11c9a143.azurecr.io.\\n>>>   2021/05/07 11:27:35 Writing ACR Details to file...\\n>>>   2021/05/07 11:27:35 Copying ACR Details file to worker nodes...\\n>>>   2021/05/07 11:27:35 Executing \\'Copy ACR Details file\\' on 10.0.0.4\\n>>>   2021/05/07 11:27:35 Begin executing \\'Copy ACR Details file\\' task on Node\\n>>>   2021/05/07 11:27:35 \\'Copy ACR Details file\\' task Node result: succeeded\\n>>>   2021/05/07 11:27:35 Copy ACR Details file succeeded on 10.0.0.4. Output: \\n>>>   >>>   \\n>>>   >>>   \\n>>>   2021/05/07 11:27:35 Successfully retrieved ACR Credentials from EMS.\\n>>>   2021/05/07 11:27:35 EMS returned 38d02f2005824c85859d3a5c11c9a143.azurecr.io for environment proj7-h\\n>>>   2021/05/07 11:27:35 Save docker credentials for image 38d02f2005824c85859d3a5c11c9a143.azurecr.io/azureml/azureml_a66eb09a2050c837952a91674b3559a2 in /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/wd/docker_login_F088A5D075E4CA21\\n>>>   2021/05/07 11:27:35 start login to the docker registry\\n>>>   2021/05/07 11:27:35 Successfully logged into the docker registry.\\n>>>   2021/05/07 11:27:35 Start run pull docker image command\\n>>>   2021/05/07 11:27:36 Not exporting to RunHistory as the exporter is either stopped or there is no data.\\n>>>   Stopped: false\\n>>>   OriginalData: 18\\n>>>   FilteredData: 0.\\n>>>   2021/05/07 11:28:08 Pull docker image succeeded.\\n>>>   2021/05/07 11:28:08 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/wd/docker_login_F088A5D075E4CA21\\n>>>   2021/05/07 11:28:08 Pull docker image time: 33.173155448s\\n>>>   \\n>>>   2021/05/07 11:28:08 Docker Version that this nodes use are: 19.03.14+azure\\n>>>   \\n>>>   2021/05/07 11:28:08 Start to getting gpu count by running nvidia-smi command\\n>>>   2021/05/07 11:28:08 GPU : GPU 0: Tesla K80 (UUID: GPU-86853283-a7d7-86e0-d63f-0d85e158969a)\\n>>>   2021/05/07 11:28:08 Setting the memory limit for docker container to be 55987 MB\\n>>>   2021/05/07 11:28:08 The env variable file size is 38226 bytes\\n>>>   2021/05/07 11:28:08 Creating parent cgroup \\'preprocessing_1620386671_6f8c3935\\' for Containers used in Job\\n>>>   2021/05/07 11:28:08 Add parent cgroup \\'preprocessing_1620386671_6f8c3935\\' to container \\'preprocessing_1620386671_6f8c3935\\'\\n>>>   2021/05/07 11:28:08 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\\n>>>   2021/05/07 11:28:08 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,preprocessing_1620386671_6f8c3935,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/certs:/mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,--gpus,all,-m,55987m,-v,/mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/wd:/mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935:/mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/preprocessing_1620386671_6f8c3935/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/preprocessing_1620386671_6f8c3935/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/config/.batchai.envlist,--cgroup-parent=/preprocessing_1620386671_6f8c3935/,--shm-size,2g\\n>>>   2021/05/07 11:28:08 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/preprocessing_1620386671_6f8c3935/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/preprocessing_1620386671_6f8c3935/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \\n>>>   2021/05/07 11:28:08 the binding /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935:/mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935 \\n>>>   2021/05/07 11:28:08 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,preprocessing_1620386671_6f8c3935,--gpus,all,-m,55987m,-w,/mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/config/.batchai.envlist,--cgroup-parent=/preprocessing_1620386671_6f8c3935/,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935:/mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935,-v,/mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/wd:/mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/wd,-v,/mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/certs:/mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/certs\\n>>>   2021/05/07 11:28:08 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name preprocessing_1620386671_6f8c3935 --gpus all -m 55987m -w /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/config/.batchai.envlist --cgroup-parent=/preprocessing_1620386671_6f8c3935/ --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935:/mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935 -v /mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/wd:/mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/wd -v /mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/certs:/mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/certs -d -it --privileged --net=host 38d02f2005824c85859d3a5c11c9a143.azurecr.io/azureml/azureml_a66eb09a2050c837952a91674b3559a2\\n>>>   2021/05/07 11:28:08 Check if container preprocessing_1620386671_6f8c3935 already exist exited with 0, \\n>>>   \\n>>>   2021/05/07 11:28:08 Check if container preprocessing_1620386671_6f8c3935 already exist exited with 0, \\n>>>   \\n>>>   2021/05/07 11:28:11 Attempt 1 of http call to https://westeurope.api.azureml.ms/history/v1.0/private/subscriptions/b9053cbf-be55-4e83-8c03-d6b0eb90cb5a/resourceGroups/Projet_7/providers/Microsoft.MachineLearningServices/workspaces/projet_7/runs/preprocessing_1620386671_6f8c3935/spans\\n>>>   2021/05/07 11:28:24 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \\n>>>   2021/05/07 11:28:24 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \\n>>>   2021/05/07 11:28:24 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-d0aae475bca74718f296ba48e0cc1c9b-cb6d4eeac0853290-01 -sshRequired=false] \\n>>>   2021/05/07 11:28:24 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-d0aae475bca74718f296ba48e0cc1c9b-cb6d4eeac0853290-01 -sshRequired=false] \\n>>>   2021/05/07 11:28:24 Container ssh is not required for job type.\\n>>>   2021/05/07 11:28:24 Starting docker container succeeded.\\n>>>   2021/05/07 11:28:24 Starting docker container succeeded.\\n>>>   2021/05/07 11:28:24 Disk space after starting docker container: 320875MB\\n>>>   2021/05/07 11:28:24 Begin execution of runSpecialJobTask\\n>>>   2021/05/07 11:28:24 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935/azureml_compute_logs\\n>>>   2021/05/07 11:28:24 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_ca6b2b150ca6091db30bfc50f017762f/bin/python /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935-setup/job_prep.py --snapshots \\'[{\"Id\":\"db65c98b-ac29-48d3-aa80-b630b55fbe6f\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]\\'\\n>>>   2021/05/07 11:28:24 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935/azureml_compute_logs/65_job_prep-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt\\n>>>   2021/05/07 11:28:24 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935/azureml_compute_logs/65_job_prep-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt\\n>>>   2021/05/07 11:28:24 native cmd: export AZUREML_JOB_TASK_ERROR_PATH=\\'/mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/wd/runSpecialJobTask_error.json\\';cd /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935;/azureml-envs/azureml_ca6b2b150ca6091db30bfc50f017762f/bin/python /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935-setup/job_prep.py --snapshots \\'[{\"Id\":\"db65c98b-ac29-48d3-aa80-b630b55fbe6f\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]\\'\\n>>>   2021/05/07 11:28:24 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\\n>>>   2021/05/07 11:28:24 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-d0aae475bca74718f296ba48e0cc1c9b-cb045d957d8c64e2-01 -t preprocessing_1620386671_6f8c3935 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1=\\'$\\'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH=\\'/mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/wd/runSpecialJobTask_error.json\\';cd /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935;/azureml-envs/azureml_ca6b2b150ca6091db30bfc50f017762f/bin/python /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935-setup/job_prep.py --snapshots \\'[{\"Id\":\"db65c98b-ac29-48d3-aa80-b630b55fbe6f\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]\\'\\n>>>   2021/05/07 11:28:26 Not exporting to RunHistory as the exporter is either stopped or there is no data.\\n>>>   Stopped: false\\n>>>   OriginalData: 1\\n>>>   FilteredData: 0.\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: job preparation exited with code 0 and err <nil>\\n>>>   \\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:25.846566] Entering job preparation.\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:28.470008] Starting job preparation.\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:28.470042] Extracting the control code.\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:28.601967] fetching and extracting the control code on master node.\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:28.601997] Starting extract_project.\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:28.602034] Starting to extract zip file.\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:30.053055] Finished extracting zip file.\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:30.492081] Using urllib.request Python 3.0 or later\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:30.492133] Start fetching snapshots.\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:30.492176] Start fetching snapshot.\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:30.492207] Retrieving project from snapshot: db65c98b-ac29-48d3-aa80-b630b55fbe6f\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 53\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:31.231875] Finished fetching snapshot.\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:31.231905] Finished fetching snapshots.\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:31.231916] Finished extract_project.\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:31.265828] Finished fetching and extracting the control code.\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:31.271037] downloadDataStore - Download from datastores if requested.\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:31.272168] Start run_history_prep.\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:31.425327] Entering context manager injector.\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:31.588823] downloadDataStore completed\\n>>>   2021/05/07 11:28:31 runSpecialJobTask: preparation: [2021-05-07T11:28:31.590557] Job preparation is complete.\\n>>>   2021/05/07 11:28:31 Execution of runSpecialJobTask completed\\n>>>   2021/05/07 11:28:31 Not exporting to RunHistory as the exporter is either stopped or there is no data.\\n>>>   Stopped: false\\n>>>   OriginalData: 3\\n>>>   FilteredData: 0.\\n>>>   2021/05/07 11:28:31 Process Exiting with Code:  0\\n>>>   2021/05/07 11:28:32 All App Insights Logs was send successfully\\n>>>   \\n2021-05-07T11:28:32Z 127.0.0.1 slots=1 max-slots=1\\n2021-05-07T11:28:32Z launching Custom job\\n2021-05-07T11:29:37Z job exited with code 0\\n2021-05-07T11:29:37Z Executing \\'JobRelease task\\' on 10.0.0.4\\n2021-05-07T11:29:41Z JobRelease task succeeded on 10.0.0.4. Output: \\n>>>   2021/05/07 11:29:37 Starting App Insight Logger for task:  jobRelease\\n>>>   2021/05/07 11:29:37 Version: 3.0.01576.0004 Branch: .SourceBranch Commit: 5216581\\n>>>   2021/05/07 11:29:37 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935/azureml_compute_logs\\n>>>   2021/05/07 11:29:37 runSpecialJobTask: Raw cmd for postprocessing is passed is: export AZ_BATCHAI_RUN_STATUS=\\'SUCCEEDED\\';export AZ_BATCHAI_LOG_UPLOAD_FAILED=\\'false\\';/azureml-envs/azureml_ca6b2b150ca6091db30bfc50f017762f/bin/python $AZ_BATCHAI_JOB_MOUNT_ROOT/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935/azureml-setup/job_release.py\\n>>>   2021/05/07 11:29:37 runSpecialJobTask: stdout path for postprocessing is passed is: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935/azureml_compute_logs/75_job_post-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt\\n>>>   2021/05/07 11:29:37 runSpecialJobTask: stderr path for postprocessing is passed is: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935/azureml_compute_logs/75_job_post-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt\\n>>>   2021/05/07 11:29:37 native cmd: export AZUREML_JOB_TASK_ERROR_PATH=\\'/mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/wd/runSpecialJobTask_error.json\\';cd /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935;export AZ_BATCHAI_RUN_STATUS=\\'SUCCEEDED\\';export AZ_BATCHAI_LOG_UPLOAD_FAILED=\\'false\\';/azureml-envs/azureml_ca6b2b150ca6091db30bfc50f017762f/bin/python $AZ_BATCHAI_JOB_MOUNT_ROOT/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935/azureml-setup/job_release.py\\n>>>   2021/05/07 11:29:37 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\\n>>>   2021/05/07 11:29:37 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-d0aae475bca74718f296ba48e0cc1c9b-ef78b6695a30fbc5-01 -t preprocessing_1620386671_6f8c3935 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1=\\'$\\'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH=\\'/mnt/batch/tasks/workitems/dca20860-360a-4b32-b1eb-7aa69a4428b2/job-1/preprocessing_162038_4b4022ea-ae1e-4ea5-9e0e-48e28fe12a75/wd/runSpecialJobTask_error.json\\';cd /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935;export AZ_BATCHAI_RUN_STATUS=\\'SUCCEEDED\\';export AZ_BATCHAI_LOG_UPLOAD_FAILED=\\'false\\';/azureml-envs/azureml_ca6b2b150ca6091db30bfc50f017762f/bin/python $AZ_BATCHAI_JOB_MOUNT_ROOT/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935/azureml-setup/job_release.py\\n>>>   2021/05/07 11:29:41 runSpecialJobTask: job postprocessing exited with code 0 and err <nil>\\n>>>   \\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: [2021-05-07T11:29:38.386759] Entering job release\\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: [2021-05-07T11:29:39.264581] Starting job release\\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: [2021-05-07T11:29:39.265073] Logging experiment finalizing status in history service.\\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: [2021-05-07T11:29:39.265227] job release stage : upload_datastore starting...Starting the daemon thread to refresh tokens in background for process with pid = 374[2021-05-07T11:29:39.265511] job release stage : start importing azureml.history._tracking in run_history_release.\\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: [2021-05-07T11:29:39.265782] job release stage : copy_batchai_cached_logs starting...\\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: \\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: [2021-05-07T11:29:39.284909] job release stage : copy_batchai_cached_logs completed...\\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: [2021-05-07T11:29:39.284967] job release stage : execute_job_release starting...\\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: \\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: [2021-05-07T11:29:39.286177] Entering context manager injector.\\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: [2021-05-07T11:29:39.293987] job release stage : upload_datastore completed...\\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: [2021-05-07T11:29:39.568641] job release stage : execute_job_release completed...\\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: [2021-05-07T11:29:39.594715] job release stage : send_run_telemetry starting...\\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: [2021-05-07T11:29:40.009340] get vm size and vm region successfully.\\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: [2021-05-07T11:29:40.760324] get compute meta data successfully.\\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: [2021-05-07T11:29:41.110879] post artifact meta request successfully.\\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: [2021-05-07T11:29:41.198648] upload compute record artifact successfully.\\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: [2021-05-07T11:29:41.198726] job release stage : send_run_telemetry completed...\\n>>>   2021/05/07 11:29:41 runSpecialJobTask: postprocessing: [2021-05-07T11:29:41.199083] Job release is complete\\n>>>   2021/05/07 11:29:41 All App Insights Logs was send successfully\\n>>>   2021/05/07 11:29:41 App Insight Client has already been closed\\n>>>   2021/05/07 11:29:41 Not exporting to RunHistory as the exporter is either stopped or there is no data.\\n>>>   Stopped: false\\n>>>   OriginalData: 3\\n>>>   FilteredData: 0.\\n>>>   \\n2021-05-07T11:29:41Z Executing \\'Job environment clean-up\\' on 10.0.0.4\\n2021-05-07T11:29:42Z Removing container preprocessing_1620386671_6f8c3935 exited with 0, preprocessing_1620386671_6f8c3935\\n\\n\\n',\n",
       "  'azureml-logs/65_job_prep-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt': '[2021-05-07T11:28:25.846566] Entering job preparation.\\r\\n[2021-05-07T11:28:28.470008] Starting job preparation.\\r\\n[2021-05-07T11:28:28.470042] Extracting the control code.\\r\\n[2021-05-07T11:28:28.601967] fetching and extracting the control code on master node.\\r\\n[2021-05-07T11:28:28.601997] Starting extract_project.\\r\\n[2021-05-07T11:28:28.602034] Starting to extract zip file.\\r\\n[2021-05-07T11:28:30.053055] Finished extracting zip file.\\r\\n[2021-05-07T11:28:30.492081] Using urllib.request Python 3.0 or later\\r\\n[2021-05-07T11:28:30.492133] Start fetching snapshots.\\r\\n[2021-05-07T11:28:30.492176] Start fetching snapshot.\\r\\n[2021-05-07T11:28:30.492207] Retrieving project from snapshot: db65c98b-ac29-48d3-aa80-b630b55fbe6f\\r\\nStarting the daemon thread to refresh tokens in background for process with pid = 53\\r\\n[2021-05-07T11:28:31.231875] Finished fetching snapshot.\\r\\n[2021-05-07T11:28:31.231905] Finished fetching snapshots.\\r\\n[2021-05-07T11:28:31.231916] Finished extract_project.\\r\\n[2021-05-07T11:28:31.265828] Finished fetching and extracting the control code.\\r\\n[2021-05-07T11:28:31.271037] downloadDataStore - Download from datastores if requested.\\r\\n[2021-05-07T11:28:31.272168] Start run_history_prep.\\r\\n[2021-05-07T11:28:31.425327] Entering context manager injector.\\r\\n[2021-05-07T11:28:31.588823] downloadDataStore completed\\r\\n[2021-05-07T11:28:31.590557] Job preparation is complete.\\r\\n',\n",
       "  'azureml-logs/70_driver_log.txt': \"2021/05/07 11:28:32 Starting App Insight Logger for task:  runTaskLet\\n2021/05/07 11:28:32 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\\n2021/05/07 11:28:32 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\\n[2021-05-07T11:28:33.862443] Entering context manager injector.\\n[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['preprocessing.py', '--input-data', 'sample'])\\nScript type = None\\n[2021-05-07T11:28:36.092749] Entering Run History Context Manager.\\n[2021-05-07T11:28:36.788128] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935\\n[2021-05-07T11:28:36.788382] Preparing to call script [preprocessing.py] with arguments:['--input-data', 'sample']\\n[2021-05-07T11:28:36.788449] After variable expansion, calling script [preprocessing.py] with arguments:['--input-data', 'sample']\\n\\nprint importing lib...\\n2021/05/07 11:28:37 Not exporting to RunHistory as the exporter is either stopped or there is no data.\\nStopped: false\\nOriginalData: 1\\nFilteredData: 0.\\nlib imported...\\nloading data...\\n[nltk_data] Downloading package stopwords to /root/nltk_data...\\n[nltk_data]   Unzipping corpora/stopwords.zip.\\nstart preprocess...\\ngetting vocab size...\\nappying seq to text...\\n\\n\\n[2021-05-07T11:29:30.364094] The experiment completed successfully. Finalizing run...\\nCleaning up all outstanding Run operations, waiting 900.0 seconds\\n2 items cleaning up...\\nCleanup took 0.19022583961486816 seconds\\n[2021-05-07T11:29:30.860853] Finished context manager injector.\\n2021/05/07 11:29:36 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\\n2021/05/07 11:29:36 Not exporting to RunHistory as the exporter is either stopped or there is no data.\\nStopped: false\\nOriginalData: 2\\nFilteredData: 0.\\n2021/05/07 11:29:36 Process Exiting with Code:  0\\n2021/05/07 11:29:37 All App Insights Logs was send successfully\\n\",\n",
       "  'azureml-logs/75_job_post-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt': '[2021-05-07T11:29:38.386759] Entering job release\\r\\n[2021-05-07T11:29:39.264581] Starting job release\\r\\n[2021-05-07T11:29:39.265073] Logging experiment finalizing status in history service.\\r\\n[2021-05-07T11:29:39.265227] job release stage : upload_datastore starting...Starting the daemon thread to refresh tokens in background for process with pid = 374[2021-05-07T11:29:39.265511] job release stage : start importing azureml.history._tracking in run_history_release.\\r\\n[2021-05-07T11:29:39.265782] job release stage : copy_batchai_cached_logs starting...\\r\\n\\r\\n[2021-05-07T11:29:39.284909] job release stage : copy_batchai_cached_logs completed...\\r\\n[2021-05-07T11:29:39.284967] job release stage : execute_job_release starting...\\r\\n\\r\\n[2021-05-07T11:29:39.286177] Entering context manager injector.\\r\\n[2021-05-07T11:29:39.293987] job release stage : upload_datastore completed...\\r\\n[2021-05-07T11:29:39.568641] job release stage : execute_job_release completed...\\r\\n[2021-05-07T11:29:39.594715] job release stage : send_run_telemetry starting...\\r\\n[2021-05-07T11:29:40.009340] get vm size and vm region successfully.\\r\\n[2021-05-07T11:29:40.760324] get compute meta data successfully.\\r\\n[2021-05-07T11:29:41.110879] post artifact meta request successfully.\\r\\n[2021-05-07T11:29:41.198648] upload compute record artifact successfully.\\r\\n[2021-05-07T11:29:41.198726] job release stage : send_run_telemetry completed...\\r\\n[2021-05-07T11:29:41.199083] Job release is complete\\r\\n',\n",
       "  'azureml-logs/process_info.json': '{\"process_name\":\"worker\",\"node_id\":\"tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p\",\"pid_in_container\":96,\"private_ip\":\"10.0.0.4\",\"log\":\"azureml-logs/70_driver_log.txt\"}\\n',\n",
       "  'azureml-logs/process_status.json': '{\"process_name\":\"worker\",\"timestamp\":\"2021-05-07T11:28:32.726618332Z\",\"status\":\"Started\"}\\n{\"process_name\":\"worker\",\"timestamp\":\"2021-05-07T11:29:36.627028332Z\",\"status\":\"Completed\"}\\n{\"process_name\":\"*\",\"timestamp\":\"2021-05-07T11:29:37.149012242Z\",\"status\":\"Terminated\"}\\n',\n",
       "  'logs/azureml/111_azureml.log': \"2021-05-07 11:28:36,124|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2021-05-07 11:28:36,124|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2021-05-07 11:28:36,163|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2021-05-07 11:28:36,163|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2021-05-07 11:28:36,597|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f773a0db040> for run source azureml.scriptrun\\n2021-05-07 11:28:36,598|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-07 11:28:36,598|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-07 11:28:36,599|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-07 11:28:36,634|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2021-05-07 11:28:36,635|azureml.core.authentication|DEBUG|Time to expire 1814161.36498 seconds\\n2021-05-07 11:28:36,635|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2021-05-07 11:28:36,635|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2021-05-07 11:28:36,665|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:28:36,665|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:28:36,666|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:28:36,666|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:28:36,666|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:28:36,666|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:28:36,667|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:28:36,704|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-05-07 11:28:36,704|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-05-07 11:28:36,785|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-05-07 11:28:36,786|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'db65c98b-ac29-48d3-aa80-b630b55fbe6f', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-05-07 11:28:36,786|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-05-07 11:28:36,786|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2021-05-07 11:28:36,787|azureml.WorkerPool|DEBUG|[START]\\n2021-05-07 11:28:36,787|azureml.SendRunKillSignal|DEBUG|[START]\\n2021-05-07 11:28:36,787|azureml.RunStatusContext|DEBUG|[START]\\n2021-05-07 11:28:36,787|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunContextManager.RunStatusContext|DEBUG|[START]\\n2021-05-07 11:28:36,787|azureml.MetricsClient|DEBUG|[START]\\n2021-05-07 11:28:36,787|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2021-05-07 11:28:36,787|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2021-05-07 11:28:36,787|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2021-05-07 11:28:36,787|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935\\n2021-05-07 11:28:36,787|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-05-07 11:28:36,787|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935\\n2021-05-07 11:29:06,600|azureml.core.authentication|DEBUG|Time to expire 1814131.399809 seconds\\n2021-05-07 11:29:08,393|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-07 11:29:08,393|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-07 11:29:08,394|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-05-07 11:29:08,394|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:08,394|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:08,395|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:08,395|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:08,395|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:08,395|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:08,395|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:08,417|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-05-07 11:29:08,417|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-05-07 11:29:08,498|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-05-07 11:29:08,499|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'db65c98b-ac29-48d3-aa80-b630b55fbe6f', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-05-07 11:29:08,499|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-05-07 11:29:09,362|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-07 11:29:09,363|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-07 11:29:09,363|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-05-07 11:29:09,364|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:09,365|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:09,365|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:09,365|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:09,367|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:09,367|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:09,367|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:19,605|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-07 11:29:19,605|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-07 11:29:19,605|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-05-07 11:29:19,606|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:19,606|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:19,606|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:19,606|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:19,607|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:19,607|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:19,607|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:19,613|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[START]\\n2021-05-07 11:29:19,613|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling patch_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-05-07 11:29:19,734|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[STOP]\\n2021-05-07 11:29:23,925|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-05-07 11:29:23,925|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-07 11:29:23,925|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-05-07 11:29:24,158|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.ArtifactsClient|DEBUG|Called upload_artifact\\n2021-05-07 11:29:24,159|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.ArtifactsClient|DEBUG|Uploading path artifact\\n2021-05-07 11:29:24,159|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-05-07 11:29:24,159|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-05-07 11:29:24,532|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-05-07 11:29:24,532|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2021-05-07 11:29:24,877|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.preprocessing_1620386671_6f8c3935/outputs/sample-pre.csv with size 399985, file size 399985.\\n2021-05-07 11:29:24,877|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935|INFO|complete is not setting status for submitted runs.\\n2021-05-07 11:29:24,878|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-05-07 11:29:24,878|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-05-07 11:29:24,878|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-07 11:29:24,878|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-05-07 11:29:24,878|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-07 11:29:24,878|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-05-07 11:29:24,878|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-05-07 11:29:24,879|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-05-07 11:29:24,879|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-07 11:29:24,879|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-05-07 11:29:24,879|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-05-07 11:29:24,879|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 1.\\n2021-05-07 11:29:24,879|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-05-07 11:29:24,879|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-05-07 11:29:24,879|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-05-07 11:29:24,880|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 1 values.\\n2021-05-07 11:29:24,880|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-05-07 11:29:24,880|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-05-07 11:29:24,880|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-05-07 11:29:24,880|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-05-07 11:29:24,880|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2021-05-07 11:29:24,881|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-05-07 11:29:24,881|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-05-07 11:29:24,884|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-05-07 11:29:24,884|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-05-07 11:29:24,884|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-05-07 11:29:24,884|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-05-07 11:29:24,884|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2021-05-07 11:29:24,885|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-05-07 11:29:24,885|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-07 11:29:24,885|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-05-07 11:29:24,885|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2021-05-07 11:29:25,085|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-05-07 11:29:25,135|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2021-05-07 11:29:25,135|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2021-05-07 11:29:25,135|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2021-05-07 11:29:25,136|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Waiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 8.749961853027344e-05 seconds.\\n\\n2021-05-07 11:29:25,136|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-07 11:29:25,136|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-05-07 11:29:25,136|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-05-07 11:29:25,136|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-05-07 11:29:25,212|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-05-07 11:29:30,218|azureml._restclient.clientbase|DEBUG|ClientBase: Calling update_status with url None\\n2021-05-07 11:29:30,362|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: [], excluding []\\n2021-05-07 11:29:30,362|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2021-05-07 11:29:30,499|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-05-07 11:29:30,499|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935\\n2021-05-07 11:29:30,499|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935 to /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935\\n2021-05-07 11:29:30,499|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/preprocessing_1620386671_6f8c3935/mounts/workspaceblobstore/azureml/preprocessing_1620386671_6f8c3935\\n2021-05-07 11:29:30,499|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2021-05-07 11:29:30,499|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2021-05-07 11:29:30,499|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-05-07 11:29:30,499|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-05-07 11:29:30,499|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-07 11:29:30,500|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-05-07 11:29:30,500|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-07 11:29:30,500|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-05-07 11:29:30,500|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-05-07 11:29:30,500|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-05-07 11:29:30,500|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-07 11:29:30,500|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-05-07 11:29:30,500|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-07 11:29:30,500|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-05-07 11:29:30,501|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-07 11:29:30,501|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-05-07 11:29:30,501|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-05-07 11:29:30,501|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-05-07 11:29:30,501|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-07 11:29:30,501|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-05-07 11:29:30,501|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-05-07 11:29:30,501|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-05-07 11:29:30,592|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-05-07 11:29:30,592|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient|DEBUG|[STOP]\\n2021-05-07 11:29:30,592|azureml.MetricsClient|DEBUG|[STOP]\\n2021-05-07 11:29:30,592|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-05-07 11:29:30,592|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-07 11:29:30,592|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-05-07 11:29:30,592|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-05-07 11:29:30,593|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-05-07 11:29:30,593|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-07 11:29:30,593|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-07 11:29:30,593|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-05-07 11:29:30,593|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-05-07 11:29:30,593|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-05-07 11:29:30,593|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-07 11:29:30,593|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-05-07 11:29:30,593|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-05-07 11:29:30,593|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-05-07 11:29:30,669|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-05-07 11:29:30,669|azureml.RunStatusContext|DEBUG|[STOP]\\n2021-05-07 11:29:30,670|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-05-07 11:29:30,670|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-07 11:29:30,670|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-05-07 11:29:30,670|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-05-07 11:29:30,670|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-05-07 11:29:30,670|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-07 11:29:30,670|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-07 11:29:30,670|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-05-07 11:29:30,670|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-05-07 11:29:30,670|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-05-07 11:29:30,670|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-07 11:29:30,670|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-05-07 11:29:30,671|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-05-07 11:29:30,671|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-05-07 11:29:30,785|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-05-07 11:29:30,785|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-05-07 11:29:30,785|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-07 11:29:30,785|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-05-07 11:29:30,785|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-05-07 11:29:30,786|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-05-07 11:29:30,786|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-07 11:29:30,786|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-05-07 11:29:30,786|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-05-07 11:29:30,786|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-05-07 11:29:30,786|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-05-07 11:29:30,786|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-05-07 11:29:30,786|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-05-07 11:29:30,786|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-05-07 11:29:30,786|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-05-07 11:29:30,860|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-05-07 11:29:30,860|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2021-05-07 11:29:30,860|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2021-05-07 11:29:30,860|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2021-05-07 11:29:30,860|azureml.WorkerPool|DEBUG|[STOP]\\n\",\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': '2021-05-07 11:29:18.9013|DEBUG|EngineHost|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|Startup|MessageParser initialized|\\n2021-05-07 11:29:18.9232|DEBUG|EngineHost|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|Startup|MessageLoop initialized|\\n2021-05-07 11:29:19.2478|DEBUG|Telemetry|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|event: ActivityMigration|metrics: {}, properties: {\"prevState\":\"No version\",\"newState\":\"1\",\"success\":\"True\"}|\\n2021-05-07 11:29:20.6339|DEBUG|Telemetry|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|event: StepInfo|metrics: {}, properties: {\"blockType\":\"Microsoft.DPrep.GetDatastoreFilesBlock\",\"id\":\"0\"}|\\n2021-05-07 11:29:20.6339|DEBUG|Telemetry|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|event: StepInfo|metrics: {}, properties: {\"blockType\":\"Microsoft.DPrep.ParseDelimitedBlock\",\"id\":\"1\"}|\\n2021-05-07 11:29:20.6339|DEBUG|Telemetry|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|event: StepInfo|metrics: {}, properties: {\"blockType\":\"Microsoft.DPrep.DropColumnsBlock\",\"id\":\"2\"}|\\n2021-05-07 11:29:20.6339|DEBUG|Telemetry|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|event: StepInfo|metrics: {}, properties: {\"blockType\":\"Microsoft.DPrep.SetColumnTypesBlock\",\"id\":\"3\"}|\\n2021-05-07 11:29:20.6339|DEBUG|Telemetry|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|event: StepInfo|metrics: {}, properties: {\"blockType\":\"Microsoft.DPrep.SetRsLexContextBlock\",\"id\":\"4\"}|\\n2021-05-07 11:29:20.6419|DEBUG|Caching|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|CachingOrchestrator|Starting cached execution|{\\n  \"CachePath\": null,\\n  \"Exception\": null\\n}\\n2021-05-07 11:29:20.6554|DEBUG|Caching|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|CachingOrchestrator|Resolving activity reference|{\\n  \"CachePath\": null,\\n  \"Exception\": null\\n}\\n2021-05-07 11:29:20.6554|DEBUG|Caching|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|CachingOrchestrator|No cache block found|{\\n  \"CachePath\": null,\\n  \"Exception\": null\\n}\\n2021-05-07 11:29:20.6670|DEBUG|DynamicPythonPathCLexExecutor|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|EnsureCLexExecutorReady|No more tasks in progress. Creating new CLexExecutor.|\\n2021-05-07 11:29:20.6886|INFO|CLexExecutor|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|ExecuteLariatScriptAsync|Start Execution|{\\n  \"Id\": \"1d6bfacf-85d7-4bdf-bfa8-8cb2bf6af6f1\"\\n}\\n2021-05-07 11:29:20.7538|DEBUG|CLex|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|MapReduceExecutor|Execution started|{\\n  \"ExecutionId\": \"229e288f-cb83-48a1-a254-6411db2c9297\",\\n  \"Main\": \"G4zAbImCOhLhvC4Wg0us+OrrnRhVssYzeVMzMy0XrRs=\"\\n}\\n2021-05-07 11:29:20.8120|INFO|EngineServer|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|HandleRequest|Received request from Python host.|\\n2021-05-07 11:29:20.8120|INFO|EngineServer|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|HandleRequest|Processing request from Python host for operation: resolve_datastore.|\\n2021-05-07 11:29:20.8349|INFO|DatastoreResolver|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|Resolve|Resolving auth and host for datastore: b9053cbf-be55-4e83-8c03-d6b0eb90cb5a,Projet_7,projet_7,dataset_projet7 using python host.|\\n2021-05-07 11:29:22.0788|DEBUG|CLex|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|MapReduceExecutor|Execution Succeeded|{\\n  \"ExecutionId\": \"229e288f-cb83-48a1-a254-6411db2c9297\",\\n  \"Main\": \"G4zAbImCOhLhvC4Wg0us+OrrnRhVssYzeVMzMy0XrRs=\"\\n}\\n2021-05-07 11:29:22.0842|DEBUG|Caching|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|CachingOrchestrator|Cached execution completed|{\\n  \"CachePath\": null,\\n  \"Exception\": null\\n}\\n',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': '2021-05-07 11:29:19.2478|DEBUG|Telemetry|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|event: ActivityMigration|metrics: {}, properties: {\"prevState\":\"No version\",\"newState\":\"1\",\"success\":\"True\"}|\\n2021-05-07 11:29:20.6339|DEBUG|Telemetry|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|event: StepInfo|metrics: {}, properties: {\"blockType\":\"Microsoft.DPrep.GetDatastoreFilesBlock\",\"id\":\"0\"}|\\n2021-05-07 11:29:20.6339|DEBUG|Telemetry|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|event: StepInfo|metrics: {}, properties: {\"blockType\":\"Microsoft.DPrep.ParseDelimitedBlock\",\"id\":\"1\"}|\\n2021-05-07 11:29:20.6339|DEBUG|Telemetry|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|event: StepInfo|metrics: {}, properties: {\"blockType\":\"Microsoft.DPrep.DropColumnsBlock\",\"id\":\"2\"}|\\n2021-05-07 11:29:20.6339|DEBUG|Telemetry|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|event: StepInfo|metrics: {}, properties: {\"blockType\":\"Microsoft.DPrep.SetColumnTypesBlock\",\"id\":\"3\"}|\\n2021-05-07 11:29:20.6339|DEBUG|Telemetry|l_71a5c4f1-ff15-4fbc-aa07-115256a22fe3|event: StepInfo|metrics: {}, properties: {\"blockType\":\"Microsoft.DPrep.SetRsLexContextBlock\",\"id\":\"4\"}|\\n',\n",
       "  'logs/azureml/job_prep_azureml.log': '2021-05-07 11:28:31,392|azureml|DEBUG|Execute Job Prep Inputs:: kwargs: {}\\n',\n",
       "  'logs/azureml/job_release_azureml.log': \"2021-05-07 11:29:39,296|azureml|DEBUG|Execute Job Release Inputs:: kwargs: {'disable_output_upload': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2021-05-07 11:29:39,297|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2021-05-07 11:29:39,297|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2021-05-07 11:29:39,297|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2021-05-07 11:29:39,298|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-07 11:29:39,298|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-07 11:29:39,299|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-07 11:29:39,335|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2021-05-07 11:29:39,335|azureml.core.authentication|DEBUG|Time to expire 1814098.664685 seconds\\n2021-05-07 11:29:39,335|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2021-05-07 11:29:39,335|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:39,336|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:39,336|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:39,336|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:39,336|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:39,337|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:39,337|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-07 11:29:39,362|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-05-07 11:29:39,362|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-05-07 11:29:39,566|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-05-07 11:29:39,567|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'db65c98b-ac29-48d3-aa80-b630b55fbe6f', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-05-07 11:29:39,567|azureml._SubmittedRun#preprocessing_1620386671_6f8c3935.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-05-07 11:29:39,567|azureml.WorkerPool|DEBUG|[START]\\n2021-05-07 11:29:39,568|azureml.TrackFolders|DEBUG|[START]\\n2021-05-07 11:29:39,568|azureml|DEBUG|Executing history release.\\n2021-05-07 11:29:39,568|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: [], excluding ['azureml-logs/driver_log']\\n2021-05-07 11:29:39,568|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2021-05-07 11:29:39,568|azureml.TrackFolders|DEBUG|[STOP]\\n2021-05-07 11:29:39,568|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2021-05-07 11:29:39,568|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2021-05-07 11:29:39,568|azureml.WorkerPool|DEBUG|[STOP]\\n\"},\n",
       " 'submittedBy': 'Axel Favreul'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_details_with_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2121ec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.download_file('outputs/sample-pre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1996fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj7",
   "language": "python",
   "name": "proj7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
