{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "executed-ticket",
   "metadata": {},
   "source": [
    "## Connection to Azure ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "instant-polls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.26.0 to work with projet_7\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-maine",
   "metadata": {},
   "source": [
    "## Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "greek-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dirty-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-bankruptcy",
   "metadata": {},
   "source": [
    "## Define environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "straight-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pursuant-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = Environment.from_conda_specification('proj7-h', 'env.yml')\n",
    "#env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-politics",
   "metadata": {},
   "source": [
    "## Compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "auburn-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "standard-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "cluster_name = 'cluster-projet7'\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-distributor",
   "metadata": {},
   "source": [
    "## Script preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "precise-packing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lstm/glove.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lstm/glove.py\n",
    "print('print importing lib...')\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "from azureml.core import Dataset\n",
    "#import joblib\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import pathlib\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, SimpleRNN, GRU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "import contractions\n",
    "\n",
    "print('lib imported...')\n",
    "# Get script arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n",
    "parser.add_argument(\"--glove-weight\", type=str, dest='glove_dataset_id', help='glove weight')\n",
    "parser.add_argument(\"--batch-size\", type=int, dest='batch_size')\n",
    "parser.add_argument(\"--epoch\", type=int, dest='epoch')\n",
    "parser.add_argument(\"--glove-dim\", type=int, dest='glove_dim')\n",
    "args = parser.parse_args()\n",
    "\n",
    "#set parameters\n",
    "dataset_name = args.training_dataset_id\n",
    "glove_name = args.glove_dataset_id\n",
    "batch_size = args.batch_size\n",
    "epoch = args.epoch\n",
    "glove_dim = args.glove_dim\n",
    "\n",
    "#get the experiment run context and workspace\n",
    "run = Run.get_context()\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "#loading data\n",
    "print(\"loading data...\")\n",
    "data = Dataset.get_by_name(ws, dataset_name).to_pandas_dataframe()\n",
    "glove = Dataset.get_by_name(ws, glove_name).to_pandas_dataframe()\n",
    "\n",
    "################################################################################################################################\n",
    "#                FUNCTION DEFINITION\n",
    "################################################################################################################################\n",
    "\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "\n",
    "#group = regex Return the string matched by the RE.SUB (several match by tweet)\n",
    "\n",
    "def hashtag(text):\n",
    "    text = text.group()\n",
    "    hashtag_body = text[1:]\n",
    "    if hashtag_body.isupper():\n",
    "        result = \"<hashtag> {} <allcaps>\".format(hashtag_body.lower())\n",
    "    else:\n",
    "        result = \" \".join([\"<hashtag>\"] + re.split(r\"(?=[A-Z])\", hashtag_body, flags=FLAGS))\n",
    "    return result\n",
    "\n",
    "def allcaps(text):\n",
    "    text = text.group()\n",
    "    return text.lower()+\" <allcaps> \"\n",
    "\n",
    "def repeat(text):\n",
    "    text = text.group()\n",
    "    t = re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
    "    if text == t:\n",
    "        return text\n",
    "    else:\n",
    "        return t+' <repeat> '\n",
    "\n",
    "def pps_glove(text):\n",
    "    # Different regex parts to combined for smiley faces  \n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`\\-]?\"\n",
    "\n",
    "    # function so code less repetitive\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    #separator for backslash to identify the two words \n",
    "    text = re_sub(r\"/\",\" / \")\n",
    "    text = re_sub(r\"<3\",\"<heart>\")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "    text = re_sub(r\"#\\w+\", hashtag)  \n",
    "    # tag in the word from the repeating letter until the end yeeees ==> text=eees =transform=> es <repeat>\n",
    "    text = re_sub(r'(.)\\1{2,}\\w+', repeat)\n",
    "    # tag repeating letter with a space just before (for this !!!!!!)\n",
    "    text = re_sub(r' (.)\\1{2,}', repeat)\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "    text = re_sub(r\"([a-zA-Z<>()])([?!.:;,])\", r\"\\1 \\2\")\n",
    "    text = re_sub(r\"\\(([a-zA-Z<>]+)\\)\", r\"( \\1 )\")\n",
    "    #flag allcaps \n",
    "    text = re_sub(r\" ([A-Z]){2,} \", allcaps)\n",
    "\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "def contraction(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def remove_apostrophe(text):\n",
    "    return re.sub(r\"['`Â´()]\", r\" \", text, flags=FLAGS)\n",
    "\n",
    "def seq_to_text(seq):\n",
    "    txt = ' '.join(seq)\n",
    "    return txt\n",
    "\n",
    "##################################################################################################################################\n",
    "#                                                     PREPROCESSING\n",
    "#################################################################################################################################\n",
    "\n",
    "\n",
    "print('start preprocess...')\n",
    "\n",
    "#main function\n",
    "data['text'] = data['text'].apply(pps_glove)\n",
    "\n",
    "#contraction (after smiley and flag)\n",
    "data['text'] = data['text'].apply(contraction)\n",
    "\n",
    "#apostrophre separation for you're, brother's, i'm etc (after contraction) replace with a space\n",
    "data['text'] = data['text'].apply(remove_apostrophe)\n",
    "\n",
    "#turn into word sequence for counter\n",
    "data['text'] = data['text'].apply(lambda x: x.split())\n",
    "\n",
    "################################################################################################################################\n",
    "#                                                 VOCABULARY and EMBEDDING MATRIX\n",
    "################################################################################################################################\n",
    "\n",
    "# load embedding vector from glove xxx dimension into a dict\n",
    "coefs = []\n",
    "word = []\n",
    "word = [w for w in glove.iloc[:,0].values]\n",
    "coefs = [val for val in glove.iloc[:,1:].values]\n",
    "embeddings_index = dict(zip(word, coefs))\n",
    "\n",
    "#vocabulary\n",
    "vocab = Counter()\n",
    "for x in data['text']:\n",
    "    vocab.update(x)\n",
    "    \n",
    "#exatract words appearing only once or twice in the corpus\n",
    "vocab_low_freq = []\n",
    "vocab_low_freq = [w for w,c in vocab.most_common() if c<3]\n",
    "\n",
    "#filter\n",
    "for w in vocab_low_freq:\n",
    "    del vocab[w]\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "#back to text for tokenizer entry\n",
    "print('applying seq to text...')\n",
    "data['text'] = data['text'].apply(seq_to_text)\n",
    "\n",
    "################################################################################################################################\n",
    "#                                                       TOKENIZER AND SPLIT\n",
    "################################################################################################################################\n",
    "\n",
    "X1 = data.text.astype(str)\n",
    "y1 = data.label\n",
    "\n",
    "#Tokenizer / seq and padding\n",
    "t = Tokenizer(num_words=vocab_size)\n",
    "t.fit_on_texts(X1)\n",
    "seq1 = t.texts_to_sequences(X1)\n",
    "\n",
    "#padding\n",
    "seq_pad1 = sequence.pad_sequences(seq1)\n",
    "\n",
    "#embedding matrix de dimension vocab_size glove_dim match our vocabulary with glove vocab\n",
    "embedding_matrix = np.zeros((len(t.word_index)+1, glove_dim))\n",
    "\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "         # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "#determining max length of review\n",
    "max_l = seq_pad1.shape[1]\n",
    "        \n",
    "#split\n",
    "X_train1, X_val1, Y_train1, Y_val1 = train_test_split(seq_pad1, y1, test_size=0.15, random_state=2)\n",
    "\n",
    "################################################################################################################################\n",
    "#                                                       MODEL\n",
    "################################################################################################################################\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "#Embedding\n",
    "model2.add(Embedding(len(t.word_index)+1,\n",
    "                     output_dim = glove_dim,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length = max_l,\n",
    "                     #training false so that weigth are not updated\n",
    "                    trainable=False))\n",
    "\n",
    "#recurrent layer\n",
    "model2.add(LSTM(128, \n",
    "                #basique activation tanh\n",
    "                activation = 'tanh',\n",
    "                #return seq false unless other LSTM layer\n",
    "                return_sequences=False, \n",
    "                dropout=0.1))\n",
    "\n",
    "#fully connected\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "\n",
    "#drop out for overfitting\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "#output layer with sigmoid pour proba\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#compile\n",
    "history = model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']) #, 'AUC'])\n",
    "\n",
    "#Adding callbacks\n",
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1,patience=3)  \n",
    "mc = ModelCheckpoint('best_model_glove', monitor='accuracy', mode='max', save_best_only=True,verbose=1)  \n",
    "\n",
    "################################################################################################################################\n",
    "#                                                       TRAINING\n",
    "################################################################################################################################\n",
    "\n",
    "model2.fit(X_train1,\n",
    "           Y_train1,\n",
    "           epochs=epoch,\n",
    "           batch_size = batch_size,\n",
    "           validation_data = (X_val1, Y_val1),\n",
    "           callbacks=[es, mc])\n",
    "\n",
    "#Evaluate\n",
    "accuracy = model2.evaluate(X_val1, Y_val1) #, auc\n",
    "\n",
    "#load metrics in run\n",
    "run.log_list('accuracy', accuracy)\n",
    "\n",
    "\n",
    "# Save model\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "os.makedirs('outputs/model', exist_ok=True)\n",
    "# serialize NN architecture to JSON\n",
    "model_json = model2.to_json()\n",
    "# save model JSON\n",
    "with open('./outputs/model/model.json', 'w') as f:\n",
    "    f.write(model_json)\n",
    "# save model weights\n",
    "model2.save_weights('./outputs/model/model.glove')\n",
    "print(\"model saved in ./outputs/model folder\")\n",
    "\n",
    "\n",
    "\n",
    "run.complete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "veterinary-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-subscriber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4a44ebb6d242a68d4f80e44bc7e74f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/glove_1621702040_e34ad639?wsid=/subscriptions/b9053cbf-be55-4e83-8c03-d6b0eb90cb5a/resourcegroups/Projet_7/workspaces/projet_7&tid=33e47288-d1e1-43e8-b65b-4ba7bfd37a9f\", \"run_id\": \"glove_1621702040_e34ad639\", \"run_properties\": {\"run_id\": \"glove_1621702040_e34ad639\", \"created_utc\": \"2021-05-22T16:47:20.097495Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"f952c1a5-985c-4a0f-8ca2-ef88c671530e\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_35584181820539b8e2fca25a37382c911ede7cbef41fbdc515b3f910df03faca_p.txt\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1621702040_e34ad639/azureml-logs/55_azureml-execution-tvmps_35584181820539b8e2fca25a37382c911ede7cbef41fbdc515b3f910df03faca_p.txt?sv=2019-02-02&sr=b&sig=GdP1D6e0kFrhLLUyLGNb1mKQMqlblu4%2F50uDBhOhKKM%3D&st=2021-05-22T16%3A41%3A39Z&se=2021-05-23T00%3A51%3A39Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_35584181820539b8e2fca25a37382c911ede7cbef41fbdc515b3f910df03faca_p.txt\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1621702040_e34ad639/azureml-logs/65_job_prep-tvmps_35584181820539b8e2fca25a37382c911ede7cbef41fbdc515b3f910df03faca_p.txt?sv=2019-02-02&sr=b&sig=FOHVENJ8Eh%2BKJcXMfQmYhLUt1we77WpYH9TNwN93S3M%3D&st=2021-05-22T16%3A41%3A39Z&se=2021-05-23T00%3A51%3A39Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1621702040_e34ad639/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=8MgAtE67AwmxULNGRV7Yol5t6Tp3l9WFPKa4pYqRn8I%3D&st=2021-05-22T16%3A41%3A39Z&se=2021-05-23T00%3A51%3A39Z&sp=r\", \"azureml-logs/process_info.json\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1621702040_e34ad639/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=JlGggw4IDb8EUGIroLtdZVlY%2F1Sw3nEY45LXFHjNeXA%3D&st=2021-05-22T16%3A41%3A39Z&se=2021-05-23T00%3A51%3A39Z&sp=r\", \"azureml-logs/process_status.json\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1621702040_e34ad639/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=C4%2BZXBk6ya3i3Zd6jiNTqEBw6PpoWBZwA5ptXbSK2Ns%3D&st=2021-05-22T16%3A41%3A39Z&se=2021-05-23T00%3A51%3A39Z&sp=r\", \"logs/azureml/111_azureml.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1621702040_e34ad639/logs/azureml/111_azureml.log?sv=2019-02-02&sr=b&sig=mAoeojJ4rWBEJvAM165Tyuvq2WSyX64rF3igzMx7i%2FI%3D&st=2021-05-22T16%3A42%3A11Z&se=2021-05-23T00%3A52%3A11Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1621702040_e34ad639/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=WMf3%2FRtc3LsBAUheUArf08cwKGhImGpX0Er%2BsVjegtA%3D&st=2021-05-22T16%3A42%3A11Z&se=2021-05-23T00%3A52%3A11Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1621702040_e34ad639/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=lHTZPSSfS7bgU09oHmsX7VjpikVMK6VS4r027Oe4IwU%3D&st=2021-05-22T16%3A42%3A11Z&se=2021-05-23T00%3A52%3A11Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.glove_1621702040_e34ad639/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=lJhrfetLbgq8%2BK%2BV9cD5%2BWfiCUEa4KDBjdse2p6QjEk%3D&st=2021-05-22T16%3A42%3A11Z&se=2021-05-23T00%3A52%3A11Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\", \"logs/azureml/job_prep_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_35584181820539b8e2fca25a37382c911ede7cbef41fbdc515b3f910df03faca_p.txt\"], [\"azureml-logs/65_job_prep-tvmps_35584181820539b8e2fca25a37382c911ede7cbef41fbdc515b3f910df03faca_p.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"logs/azureml/111_azureml.log\"]], \"run_duration\": \"0:24:44\", \"run_number\": \"1621702040\", \"run_queued_details\": {\"status\": \"Running\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"2021-05-22 16:51:22,550|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2021-05-22 16:51:22,551|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2021-05-22 16:51:22,636|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2021-05-22 16:51:22,636|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2021-05-22 16:51:23,022|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f8baa637160> for run source azureml.scriptrun\\n2021-05-22 16:51:23,023|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-22 16:51:23,023|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-22 16:51:23,024|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-05-22 16:51:23,060|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2021-05-22 16:51:23,061|azureml.core.authentication|DEBUG|Time to expire 1814156.939004 seconds\\n2021-05-22 16:51:23,061|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2021-05-22 16:51:23,061|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2021-05-22 16:51:23,097|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:23,097|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:23,098|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:23,098|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:23,098|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:23,098|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:23,098|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:23,133|azureml._SubmittedRun#glove_1621702040_e34ad639.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-05-22 16:51:23,133|azureml._SubmittedRun#glove_1621702040_e34ad639.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-05-22 16:51:23,210|azureml._SubmittedRun#glove_1621702040_e34ad639.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-05-22 16:51:23,210|azureml._SubmittedRun#glove_1621702040_e34ad639|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'f952c1a5-985c-4a0f-8ca2-ef88c671530e', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-05-22 16:51:23,210|azureml._SubmittedRun#glove_1621702040_e34ad639.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-05-22 16:51:23,211|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2021-05-22 16:51:23,211|azureml.WorkerPool|DEBUG|[START]\\n2021-05-22 16:51:23,211|azureml.SendRunKillSignal|DEBUG|[START]\\n2021-05-22 16:51:23,211|azureml.RunStatusContext|DEBUG|[START]\\n2021-05-22 16:51:23,211|azureml._SubmittedRun#glove_1621702040_e34ad639.RunContextManager.RunStatusContext|DEBUG|[START]\\n2021-05-22 16:51:23,211|azureml.MetricsClient|DEBUG|[START]\\n2021-05-22 16:51:23,211|azureml._SubmittedRun#glove_1621702040_e34ad639.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2021-05-22 16:51:23,211|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2021-05-22 16:51:23,211|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2021-05-22 16:51:23,211|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/glove_1621702040_e34ad639/mounts/workspaceblobstore/azureml/glove_1621702040_e34ad639\\n2021-05-22 16:51:23,211|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-05-22 16:51:23,212|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/projet_7/azureml/glove_1621702040_e34ad639/mounts/workspaceblobstore/azureml/glove_1621702040_e34ad639\\n2021-05-22 16:51:53,025|azureml.core.authentication|DEBUG|Time to expire 1814126.974498 seconds\\n2021-05-22 16:51:54,329|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-22 16:51:54,329|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-22 16:51:54,329|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-05-22 16:51:54,329|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:54,330|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:54,330|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:54,330|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:54,330|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:54,331|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:54,331|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:54,352|azureml._SubmittedRun#glove_1621702040_e34ad639.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-05-22 16:51:54,352|azureml._SubmittedRun#glove_1621702040_e34ad639.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-05-22 16:51:54,420|azureml._SubmittedRun#glove_1621702040_e34ad639.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-05-22 16:51:54,420|azureml._SubmittedRun#glove_1621702040_e34ad639|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'f952c1a5-985c-4a0f-8ca2-ef88c671530e', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-05-22 16:51:54,420|azureml._SubmittedRun#glove_1621702040_e34ad639.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-05-22 16:51:54,789|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-22 16:51:54,789|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-22 16:51:54,790|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-05-22 16:51:54,790|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:54,791|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:54,792|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:54,792|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:54,794|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:54,794|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:51:54,799|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:52:05,404|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-22 16:52:05,404|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-22 16:52:05,405|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-05-22 16:52:05,405|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:52:05,406|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:52:05,406|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:52:05,406|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:52:05,406|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:52:05,406|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:52:05,406|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:52:05,412|azureml._SubmittedRun#glove_1621702040_e34ad639.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[START]\\n2021-05-22 16:52:05,413|azureml._SubmittedRun#glove_1621702040_e34ad639.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling patch_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-05-22 16:52:05,531|azureml._SubmittedRun#glove_1621702040_e34ad639.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[STOP]\\n2021-05-22 16:52:11,356|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-05-22 16:52:11,356|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-05-22 16:52:11,356|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-05-22 16:52:11,357|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:52:11,357|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:52:11,357|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:52:11,357|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:52:11,358|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:52:11,358|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:52:11,358|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-05-22 16:52:11,363|azureml._SubmittedRun#glove_1621702040_e34ad639.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[START]\\n2021-05-22 16:52:11,363|azureml._SubmittedRun#glove_1621702040_e34ad639.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling patch_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-05-22 16:52:11,487|azureml._SubmittedRun#glove_1621702040_e34ad639.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[STOP]\\n2021-05-22 16:52:23,041|azureml.core.authentication|DEBUG|Time to expire 1814096.958934 seconds\\n2021-05-22 16:52:53,056|azureml.core.authentication|DEBUG|Time to expire 1814066.943346 seconds\\n2021-05-22 16:53:23,051|azureml.core.authentication|DEBUG|Time to expire 1814036.948307 seconds\\n2021-05-22 16:53:53,067|azureml.core.authentication|DEBUG|Time to expire 1814006.932699 seconds\\n2021-05-22 16:54:23,528|azureml.core.authentication|DEBUG|Time to expire 1813976.471454 seconds\\n2021-05-22 16:54:53,070|azureml.core.authentication|DEBUG|Time to expire 1813946.929372 seconds\\n2021-05-22 16:55:23,074|azureml.core.authentication|DEBUG|Time to expire 1813916.925227 seconds\\n2021-05-22 16:55:53,082|azureml.core.authentication|DEBUG|Time to expire 1813886.917124 seconds\\n2021-05-22 16:56:23,088|azureml.core.authentication|DEBUG|Time to expire 1813856.911897 seconds\\n2021-05-22 16:56:53,090|azureml.core.authentication|DEBUG|Time to expire 1813826.910028 seconds\\n2021-05-22 16:57:23,099|azureml.core.authentication|DEBUG|Time to expire 1813796.900671 seconds\\n2021-05-22 16:57:53,101|azureml.core.authentication|DEBUG|Time to expire 1813766.898781 seconds\\n2021-05-22 16:58:23,102|azureml.core.authentication|DEBUG|Time to expire 1813736.897527 seconds\\n2021-05-22 16:58:53,104|azureml.core.authentication|DEBUG|Time to expire 1813706.895482 seconds\\n2021-05-22 16:59:23,106|azureml.core.authentication|DEBUG|Time to expire 1813676.893646 seconds\\n2021-05-22 16:59:53,112|azureml.core.authentication|DEBUG|Time to expire 1813646.887737 seconds\\n2021-05-22 17:00:23,116|azureml.core.authentication|DEBUG|Time to expire 1813616.883748 seconds\\n2021-05-22 17:00:53,117|azureml.core.authentication|DEBUG|Time to expire 1813586.882776 seconds\\n2021-05-22 17:01:23,122|azureml.core.authentication|DEBUG|Time to expire 1813556.877366 seconds\\n2021-05-22 17:01:53,124|azureml.core.authentication|DEBUG|Time to expire 1813526.875536 seconds\\n2021-05-22 17:02:23,131|azureml.core.authentication|DEBUG|Time to expire 1813496.868718 seconds\\n2021-05-22 17:02:53,134|azureml.core.authentication|DEBUG|Time to expire 1813466.865388 seconds\\n2021-05-22 17:03:23,137|azureml.core.authentication|DEBUG|Time to expire 1813436.862084 seconds\\n2021-05-22 17:03:53,141|azureml.core.authentication|DEBUG|Time to expire 1813406.858763 seconds\\n2021-05-22 17:04:23,149|azureml.core.authentication|DEBUG|Time to expire 1813376.850608 seconds\\n2021-05-22 17:04:53,150|azureml.core.authentication|DEBUG|Time to expire 1813346.84969 seconds\\n2021-05-22 17:05:23,156|azureml.core.authentication|DEBUG|Time to expire 1813316.843584 seconds\\n2021-05-22 17:05:53,164|azureml.core.authentication|DEBUG|Time to expire 1813286.835091 seconds\\n2021-05-22 17:06:23,172|azureml.core.authentication|DEBUG|Time to expire 1813256.827448 seconds\\n2021-05-22 17:06:53,176|azureml.core.authentication|DEBUG|Time to expire 1813226.823593 seconds\\n2021-05-22 17:07:23,184|azureml.core.authentication|DEBUG|Time to expire 1813196.81519 seconds\\n2021-05-22 17:07:53,190|azureml.core.authentication|DEBUG|Time to expire 1813166.809174 seconds\\n2021-05-22 17:08:23,198|azureml.core.authentication|DEBUG|Time to expire 1813136.801239 seconds\\n2021-05-22 17:08:53,202|azureml.core.authentication|DEBUG|Time to expire 1813106.797201 seconds\\n2021-05-22 17:09:23,211|azureml.core.authentication|DEBUG|Time to expire 1813076.788749 seconds\\n2021-05-22 17:09:53,217|azureml.core.authentication|DEBUG|Time to expire 1813046.782643 seconds\\n2021-05-22 17:10:23,221|azureml.core.authentication|DEBUG|Time to expire 1813016.778434 seconds\\n2021-05-22 17:10:53,229|azureml.core.authentication|DEBUG|Time to expire 1812986.770629 seconds\\n2021-05-22 17:11:23,232|azureml.core.authentication|DEBUG|Time to expire 1812956.767295 seconds\\n2021-05-22 17:11:53,236|azureml.core.authentication|DEBUG|Time to expire 1812926.763772 seconds\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.26.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get the registered environment\n",
    "registered_env = Environment.get(ws, 'proj7-h')\n",
    "\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory='lstm',\n",
    "                                script='glove.py',\n",
    "                                arguments = ['--input-data', 'train',\n",
    "                                            '--glove-dim', 25,\n",
    "                                            '--glove-weight', 'glove-25d',\n",
    "                                            '--batch-size', 128,\n",
    "                                            '--epoch', 50],\n",
    "                                environment=registered_env,\n",
    "                                compute_target=cluster_name) \n",
    "\n",
    "# submit the experiment\n",
    "experiment_name = 'glove'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a37fe85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size 6963\n"
     ]
    }
   ],
   "source": [
    "metrics = run.get_metrics()\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3c9807a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml-logs/55_azureml-execution-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt\n",
      "azureml-logs/65_job_prep-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt\n",
      "azureml-logs/70_driver_log.txt\n",
      "azureml-logs/75_job_post-tvmps_fcddfe71e7c57134015c48375eca90957ca8d7b718cd24a281b8724cc9352405_p.txt\n",
      "azureml-logs/process_info.json\n",
      "azureml-logs/process_status.json\n",
      "logs/azureml/111_azureml.log\n",
      "logs/azureml/dataprep/backgroundProcess.log\n",
      "logs/azureml/dataprep/backgroundProcess_Telemetry.log\n",
      "logs/azureml/job_prep_azureml.log\n",
      "logs/azureml/job_release_azureml.log\n",
      "outputs/sample-pre.csv\n"
     ]
    }
   ],
   "source": [
    "for file in run.get_file_names():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0d4fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj7",
   "language": "python",
   "name": "proj7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
